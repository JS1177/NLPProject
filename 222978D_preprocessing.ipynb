{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Context\n",
    "Goal of project is to classify resumes (not to grade resumes). Therefore, goal of preprocessing is to ensure that the text are properly normalized such that they can be properly compared. Priority should therefore be given to keywords etc. due to the specialized nature of each class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784b56be34640225"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ebd815c363cde7"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.448224200Z",
     "start_time": "2024-01-28T16:54:58.773868100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Temp\\ipykernel_61204\\2766822271.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import edit_distance as levenshteinDistance\n",
    "\n",
    "from typing_extensions import Literal, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.529861300Z",
     "start_time": "2024-01-28T16:54:59.450224700Z"
    }
   },
   "id": "26cc9ac6ac95dcab",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "VAR = {\n",
    "    'data_path': os.path.join('UpdatedResumeDataSet_T1_7.csv'),\n",
    "    'batch_size': 32,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.532369700Z",
     "start_time": "2024-01-28T16:54:59.529861300Z"
    }
   },
   "id": "c77f0d91710e6b6e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res_data_raw = pd.read_csv(VAR['data_path'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.621065400Z",
     "start_time": "2024-01-28T16:54:59.531369700Z"
    }
   },
   "id": "2fbbfd49f104e2fe",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9595 entries, 0 to 9594\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  9595 non-null   object\n",
      " 1   Resume    9595 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 150.1+ KB\n"
     ]
    }
   ],
   "source": [
    "res_data_raw.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.631753200Z",
     "start_time": "2024-01-28T16:54:59.622064200Z"
    }
   },
   "id": "8ccc3c16c91aeae7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       Category                                             Resume\n0  Data Science  qwtnrvduof Education Details \\nMay 2013 to May...\n1  Data Science  qwtnrvduof Areas of Interest Deep Learning, Co...\n2  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n3  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n4  Data Science  SKILLS C Basics, IOT, Python, MATLAB, Data Sci...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Resume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Science</td>\n      <td>qwtnrvduof Education Details \\nMay 2013 to May...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Science</td>\n      <td>qwtnrvduof Areas of Interest Deep Learning, Co...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Science</td>\n      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Science</td>\n      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Science</td>\n      <td>SKILLS C Basics, IOT, Python, MATLAB, Data Sci...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_data_raw.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.635941200Z",
     "start_time": "2024-01-28T16:54:59.627822500Z"
    }
   },
   "id": "216fb33509475e3",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac225d99793c411"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "9407"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_data_raw['Resume'].duplicated(keep='first').sum() #Check for duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.639394800Z",
     "start_time": "2024-01-28T16:54:59.634260500Z"
    }
   },
   "id": "209c2fcedb60c5a5",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res_data = res_data_raw.drop_duplicates(subset=['Resume'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.643152700Z",
     "start_time": "2024-01-28T16:54:59.636945Z"
    }
   },
   "id": "e4b0cbdd4f0df83f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Category\nJava Developer               14\nData Science                 12\nHR                           12\nDatabase                     11\nAdvocate                     10\nDotNet Developer              8\nHadoop                        8\nDevOps Engineer               8\nBusiness Analyst              8\nTesting                       8\nCivil Engineer                7\nSAP Developer                 7\nHealth and fitness            7\nPython Developer              7\nArts                          7\nAutomation Testing            7\nElectrical Engineering        6\nSales                         6\nNetwork Security Engineer     6\nETL Developer                 6\nMechanical Engineer           5\nWeb Designing                 5\nBlockchain                    5\nOperations Manager            4\nPMO                           4\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_data['Category'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.678280800Z",
     "start_time": "2024-01-28T16:54:59.642398100Z"
    }
   },
   "id": "e1195cbd300cb893",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explore Resume Text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41bf6096151b672"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwtnrvduof Education Details \n",
      "May 2013 to May 2017 BbNTGBqLmkKE   UIT-RGPV\n",
      "Data Scientist \n",
      "\n",
      "Data Scientist - Matelabs\n",
      "Skill Details \n",
      "Python- Exprience - Less than 1 year months\n",
      "Statsmodels- Exprience - 12 months\n",
      "AWS- Exprience - Less than 1 year months\n",
      "Machine learning- Exprience - Less than 1 year months\n",
      "Sklearn- Exprience - Less than 1 year months\n",
      "Scipy- Exprience - Less than 1 year months\n",
      "Keras- Exprience - Less than 1 year monthsCompany Details \n",
      "company - Matelabs\n",
      "description - ML Platform for business professionals, dummies and enthusiastsckeKJOFvWQ\n",
      "60/A Koramangala 5th block,\n",
      "Achievements/Tasks behind sukh sagar, Bengaluru,\n",
      "India                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\n",
      "treatment, outlier detection, encoding, scaling, feature selection and dimensionality reductionqunsOBcUdT\n",
      "Deployed automated classification and regression modelRYNOolXhuV\n",
      "linkedinSAJhwmUxoOcom/in/aditya-rathore-\n",
      "b4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\n",
      "ProphetiQmADshIYN\n",
      "Worked on meta-feature extracting problemisZoGErzLF\n",
      "githubBRBEGnCeAecom/rathorology\n",
      "Implemented a state of the art research paper on outlier detection for mixed attributes.\n",
      "company - Matelabs\n",
      "description - \n"
     ]
    }
   ],
   "source": [
    "sample_res = res_data['Resume'][0]\n",
    "print(sample_res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.679280400Z",
     "start_time": "2024-01-28T16:54:59.645658900Z"
    }
   },
   "id": "70ae4ab9b43dc3c5",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial Review:\n",
    "Some words are seemingly gibberish and consists of a sequence of random characters\n",
    "\n",
    "These words should be removed. However, care must be taken to ensure that other important text such as links are not classified as gibberish\n",
    "\n",
    "List of issues:\n",
    "Broken links (Solved)\n",
    "Long whitespaces (Solved)\n",
    "Combined words without clear separators https://github.com/grantjenks/python-wordsegment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6878125ef3d6a821"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'qwtnrvduof Education Details \\nMay 2013 to May 2017 BbNTGBqLmkKE   UIT-RGPV\\nData Scientist \\n\\nData Scientist - Matelabs\\nSkill Details \\nPython- Exprience - Less than 1 year months\\nStatsmodels- Exprience - 12 months\\nAWS- Exprience - Less than 1 year months\\nMachine learning- Exprience - Less than 1 year months\\nSklearn- Exprience - Less than 1 year months\\nScipy- Exprience - Less than 1 year months\\nKeras- Exprience - Less than 1 year monthsCompany Details \\ncompany - Matelabs\\ndescription - ML Platform for business professionals, dummies and enthusiastsckeKJOFvWQ\\n60/A Koramangala 5th block,\\nAchievements/Tasks behind sukh sagar, Bengaluru,\\nIndia                               Developed and deployed auto preprocessing steps of machine learning mainly missing value\\ntreatment, outlier detection, encoding, scaling, feature selection and dimensionality reductionqunsOBcUdT\\nDeployed automated classification and regression modelRYNOolXhuV\\nlinkedinSAJhwmUxoOcom/in/aditya-rathore-\\nb4600b146                           Reasearch and deployed the time series forecasting model ARIMA, SARIMAX, Holt-winter and\\nProphetiQmADshIYN\\nWorked on meta-feature extracting problemisZoGErzLF\\ngithubBRBEGnCeAecom/rathorology\\nImplemented a state of the art research paper on outlier detection for mixed attributes.\\ncompany - Matelabs\\ndescription - '"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.680590800Z",
     "start_time": "2024-01-28T16:54:59.647583600Z"
    }
   },
   "id": "43c9663538e6da95",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clean_links(potentialLinks: list):\n",
    "    \n",
    "    '''\n",
    "    Assumption: Potential link will always have at the minimum a .com\n",
    "    \n",
    "    Checks validity of link and returns cleaned link string\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(potentialLinks, list)\n",
    "    \n",
    "    http_exist = False\n",
    "    www_exist = False\n",
    "    com_exist = False\n",
    "    \n",
    "    if len(potentialLinks) < 1:\n",
    "        return []\n",
    "    \n",
    "    ret_list = []\n",
    "    \n",
    "    for link in potentialLinks:\n",
    "        \n",
    "        http_match = re.search(r'(https?)(:)?(\\/){0,2}', link)\n",
    "        www_match = re.search(r'(www)(\\.)?', link)\n",
    "        com_match = re.search(r'(\\.)?(com)', link)\n",
    "        # print('flagged', link)\n",
    "        \n",
    "        #http\n",
    "        if http_match != None:\n",
    "            http_exist = True\n",
    "        \n",
    "        #www\n",
    "        if www_match != None:\n",
    "            www_exist = True\n",
    "        \n",
    "        #com\n",
    "        if com_match != None:\n",
    "            com_exist = True\n",
    "            \n",
    "        if (com_exist) or (com_exist and www_exist) or (com_exist and www_exist and http_exist):\n",
    "            link = re.sub(r'(https?)(:)?(\\/){0,2}', 'https://', link)\n",
    "            link = re.sub(r'(www)(\\.)?', 'www.', link)\n",
    "            link = re.sub(r'(\\.)?(com)', '.com', link)\n",
    "            \n",
    "            ret_list.append(link)\n",
    "        else:\n",
    "            #Not valid link\n",
    "            ret_list.append(False)\n",
    "            \n",
    "    return ret_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.698992800Z",
     "start_time": "2024-01-28T16:54:59.653939700Z"
    }
   },
   "id": "cce23585ea4f68f3",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'qwtnrvduof education details may 2013 to may 2017 bbntgbqlmkke uit rgpv data scientist data scientist matelabs skill details python exprience less than 1 year months statsmodels exprience 12 months aws exprience less than 1 year months machine learning exprience less than 1 year months sklearn exprience less than 1 year months scipy exprience less than 1 year months keras exprience less than 1 year monthscompany details company matelabs description ml platform for business professionals dummies and enthusiastsckekjofvwq 60 a koramangala 5th block achievements tasks behind sukh sagar bengaluru india developed and deployed auto preprocessing steps of machine learning mainly missing value treatment outlier detection encoding scaling feature selection and dimensionality reductionqunsobcudt deployed automated classification and regression modelrynoolxhuv b4600b146 reasearch and deployed the time series forecasting model arima sarimax holt winter and prophetiqmadshiyn worked on meta feature extracting problemiszogerzlf implemented a state of the art research paper on outlier detection for mixed attributes company matelabs description '"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_raw_text(text: str):\n",
    "    \n",
    "    # Clean links section\n",
    "    potential_links = re.findall(\n",
    "        r'(?:(?:https?:?\\/\\/{1,2})?w{1,3}\\.?)?[a-zA-z0-9]{1,2048}\\.?[a-zA-Z0-9]{1,6}\\/\\b[/\\-a-zA-Z0-9]*\\w', text\n",
    "    ) \n",
    "    '''\n",
    "    / will flag a sequence of characters as potential links\n",
    "    \n",
    "    Optional criteions: \n",
    "    http(s)\n",
    "    //\n",
    "    www & .\n",
    "    . & com\n",
    "    '''\n",
    "    \n",
    "    finalized_links = clean_links(potential_links)\n",
    "\n",
    "    for potential_link, finalized_link in zip(potential_links, finalized_links):\n",
    "        if finalized_link == False:\n",
    "            continue\n",
    "        else:\n",
    "#             print('real_links', finalized_link)\n",
    "            text = re.sub(potential_link, ' ', text) #Remove link\n",
    "    \n",
    "    #Clean non-characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', r' ', text)\n",
    "    \n",
    "    #Normalize text\n",
    "    text = text.lower()\n",
    "\n",
    "    #Clean whitespace section\n",
    "    text = re.sub(r'[ ]{1,}', r' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean_raw_text(sample_res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.700089Z",
     "start_time": "2024-01-28T16:54:59.657157300Z"
    }
   },
   "id": "efc57f3090db2021",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_numpy(text):\n",
    "    \n",
    "    if isinstance(text, list):\n",
    "        text = np.array(text)\n",
    "        return text\n",
    "    elif isinstance(text, np.ndarray):\n",
    "        return text\n",
    "    else:\n",
    "        raise TypeError('Not a list or numpy array')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.700592700Z",
     "start_time": "2024-01-28T16:54:59.662525600Z"
    }
   },
   "id": "a8a8d57bd14dd42",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def in_english_corpus(text: list | np.ndarray, behaviour: Literal['inside', 'outside'] = 'inside'):\n",
    "    \n",
    "    text = check_numpy(text)\n",
    "\n",
    "    english_dictionary = nltk.corpus.words.raw().split('\\n')\n",
    "\n",
    "    english_dictionary = [word.lower() for word in english_dictionary] # normalize to lowercase\n",
    "    \n",
    "    word_in_dict_bool = np.isin(text, english_dictionary)\n",
    "    \n",
    "    if behaviour == 'inside':\n",
    "        return text[word_in_dict_bool]\n",
    "    elif behaviour == 'outside':\n",
    "        word_not_in_dict_bool = np.invert(word_in_dict_bool)\n",
    "        return text[word_not_in_dict_bool]\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.753840900Z",
     "start_time": "2024-01-28T16:54:59.665629800Z"
    }
   },
   "id": "837075b2fbc9d445",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clean_structured_text(text: list | np.ndarray, customer_dictionary: list = nltk.corpus.words.raw().split('\\n')):\n",
    "    \n",
    "    #TODO There may be no point to cleaning mistyped random words > Intefere with keywords > Model may have to simply learn the noise\n",
    "\n",
    "    text = check_numpy(text)\n",
    "    \n",
    "    customer_dictionary = [word.lower() for word in customer_dictionary] # normalize to lowercase\n",
    "    \n",
    "    word_in_dict_bool = np.isin(text, customer_dictionary)\n",
    "    \n",
    "    word_not_in_dict_bool = np.invert(word_in_dict_bool)\n",
    "    \n",
    "    \n",
    "    \n",
    "    words_in_dict = text[word_not_in_dict_bool]\n",
    "    \n",
    "    print(words_in_dict)\n",
    "\n",
    "# clean_structured_text(sample_lemmas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.774429400Z",
     "start_time": "2024-01-28T16:54:59.669281300Z"
    }
   },
   "id": "d48354035fc76fb",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def wordnet_tag_format(tag: str):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "    if tag.startswith('A'):\n",
    "        return 'a'\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "    \n",
    "    return 'n' #Ensure lemmatize function can run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.792430300Z",
     "start_time": "2024-01-28T16:54:59.683321300Z"
    }
   },
   "id": "60254b9a74b9fe2c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_lemmas(tagged_tokens: list[tuple], lemmatizer=nltk.stem.WordNetLemmatizer()):\n",
    "    lemmas = [lemmatizer.lemmatize(token[0], wordnet_tag_format(token[1])) for token in tagged_tokens]\n",
    "    \n",
    "    return lemmas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.797430200Z",
     "start_time": "2024-01-28T16:54:59.686827700Z"
    }
   },
   "id": "bab679f05de30967",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "--- Start Analysis ---\n",
    "### Goal:\n",
    "\n",
    "With reference to a list of possible english words, we aim to separate keywords important to job scopes and misspelled/invalid words. With the list of misspelled/invalids words, we can find the closest possible related word using Levenshtein Distance.\n",
    "\n",
    "### Theory:\n",
    "\n",
    "Since most misspelled words with random number of combinations occuringly more than once has a very small probability it is more likely that we will see keywords occur more frequently compared to misspelled words and characters of random sequence."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a58b353972d45cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_common_words_from_raw_data_ood(resumes_df: pd.DataFrame, column: str):\n",
    "    \n",
    "    resumes = resumes_df[column].to_numpy()\n",
    "    resumes = check_numpy(resumes)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    counter = Counter()\n",
    "    \n",
    "    for index, resume in enumerate(resumes):\n",
    "        normalized_resume = extract_lemmas(\n",
    "            nltk.pos_tag(\n",
    "                nltk.tokenize.word_tokenize(\n",
    "                    clean_raw_text(resume))), \n",
    "            lemmatizer)\n",
    "        \n",
    "        # out of dictionary\n",
    "        ood = in_english_corpus(normalized_resume, 'outside')\n",
    "        counter.update(ood)\n",
    "        \n",
    "        if index % 10 == 0:\n",
    "            print(index)\n",
    "        \n",
    "    return counter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.802429400Z",
     "start_time": "2024-01-28T16:54:59.692458500Z"
    }
   },
   "id": "61ec85bbd1682100",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# count = extract_common_words_from_raw_data_ood(res_data, 'Resume')\n",
    "# print(count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.804429400Z",
     "start_time": "2024-01-28T16:54:59.696433700Z"
    }
   },
   "id": "a3fca6554ace1bbb",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Output Analysis\n",
    "\n",
    "Clearly misspelled words like \"exprience\" occur most frequently, and sequence of seemingly random characters \"bbntgbqlmkkeckekjofvwq\" appeared 5 times.\n",
    "\n",
    "Conversely, keywords like \"mozilla\" which may be important to Web Designers only appeared once. Other important keywords like \"tensorflow\" and \"scikit\" only appears 5 times, the same as \"bbntgbqlmkkeckekjofvwq\". I therefore hypothesise that words such as \"bbntgbqlmkkeckekjofvwq\" occurring is not based on chance due to the miniscule probability. There is thus no apparent clear threshold/boundary between misspelled/noise words and keywords.\n",
    "\n",
    "--- End Analysis ---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db87d52b2223b323"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pipeline(filepath: str, feature_name: str):\n",
    "    \n",
    "    def total_normalize(text):\n",
    "        text = clean_raw_text(text)\n",
    "        text_tag = nltk.pos_tag(\n",
    "            nltk.word_tokenize(text)\n",
    "        )\n",
    "        text_lemmas = extract_lemmas(text_tag)\n",
    "        \n",
    "        return ' '.join(text_lemmas)\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop_duplicates(subset=[feature_name], keep='first')\n",
    "    df[feature_name] = df[feature_name].apply(total_normalize)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:54:59.825429800Z",
     "start_time": "2024-01-28T16:54:59.698992800Z"
    }
   },
   "id": "69961c6ec093dd8c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'skill r python sap hana tableau sap hana sql sap hana pal m sql sap lumira c linear program data model advance analytics scm analytics retail analytics social medium analytics nlp education detail january 2017 to january 2018 pgdm business analytics great lake institute of management illinois institute of technology january 2013 bachelor of engineering electronics and communication bengaluru karnataka new horizon college of engineering bangalore visvesvaraya technological university data science consultant consultant deloitte usi skill detail linear program exprience 6 month retail exprience 6 month retail marketing exprience 6 month scm exprience 6 month sql exprience le than 1 year month deep learn exprience le than 1 year month machine learn exprience le than 1 year month python exprience le than 1 year month r exprience le than 1 year monthscompany detail company deloitte usi description the project involve analyse historic deal and come with insight to optimize future dealsbntgbqlmkk role be give raw data carry out end to end analysis and present insight to clientckekjofvwq key responsibility extract data from client system across geographiesqunsobcudt understand and build report in tableaurynoolxhuv infer meaningful insight to optimize price and find out process blockadessajhwmuxoo technical environment r tableauiqmadshiyn industry cross industry service area cross industry product project name handwrite recognition consultant 3 monthsiszogerzlf the project involve take handwritten image and convert them to digital text image by object detection and sentence creationbrbegnceae role i be develop sentence correction functionality key responsibility gather data large enough to capture all english word train lstm model on word technical environment python industry finance service area financial service bi development project name swift consultant 8 month the project be to develop an analytics infrastructure on top of sap s 4 it would user to view financial report to respective department report also include forecasting expense role i be lead the offshore team key responsibility design develop data model for report develop etl for data flow validate various report technical environment sap hana tableau sap ao industry healthcare analytics service area life science product development project name clinical healthcare system consultant 2 month the project be to develop an analytics infrastructure on top of argus it would allow user to query faster and provide advance analytics capability role i be involve from design to deploy phase perform a lot of data restructuring and build model for insight key responsibility design develop data model for report develop and deploy analytical model validate various report technical environment data model sap hana tableau nlp industry fmcg service area trade promotion project name consumption base planning for flower food consultant 8 month the project involve set up of crm and cbp module role i be involve in key data decomposition activity and set up the base for future year forecast over the course of the project i develop various model and carry out key performance improvement key responsibility design develop hana model for decomposition develop data flow for forecast develop various view for reporting of customer sale fund validate various report in bobj technical environment data model sap hana bobj time series forecast internal initiative industry fmcg customer segmentation and rfm analysis consultant 3 month the initiative involve set up of hana python interface and advance analytics on python over the course i have successfully segment data into five core segment use k mean and carry out rfm analysis in python also develop algorithm to categorize any new customer under the defined bucket technical environment anaconda3 python3 6 hana sps12 industry telecom invoice state detection consultant 1 month the initiative be to reduce the manual effort in verify closed and open invoice manually it involve development to a decision tree to classify open close invoice this enabled effort reduction by 60 technical environment r sap pal sap hana sps12 accenture experience industry analytics cross industry in process analytics for sap senior developer 19 month accenture solution pvt ltd india the project involve development of sap analytics tool in process analytics ipa my role be to develop database object and data model to provide operational insight to client role i have develop various finance relate kpis and spearhead various deployment introduce sap predictive analytics to reduce development time and reuse functionality for kpis and prepared production planning report key responsibility involve in information gather phase design and implement sap hana data model use attribute view analytic view and calculation view develop various kpi s individually use complex sql script in calculation view create procedure in hana database take ownership and develop dashboard functionality involve in build data process algorithm to be execute in r server for cluster analysis technical environment r sap hana t sql industry cross industry accenture test accelerator for sap database developer 21 month accenture solution pvt ltd india role i have take care of all development activity for the atas tool and have also complete various deployment of the product apart from these activity i be also actively involve in maintenance of the database server production quality key responsibility analyze business requirement understand the scope get requirement clarify interact with business and further transform all requirement to generate attribute mapping document and review map specification documentation create update database object like table view store procedure function and package monitor sql server error log and application log through sql server agent prepare data flow diagram entity relationship diagram use uml responsible for design develop and normalization of database table experience in performance tune use sql profiler involve in qa uat knowledge transfer and support activity technical environment sql server 2008 2014 visual studio 2010 windows server performance monitor sql server profiler c pl sql t sql'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_resumes = pipeline('UpdatedResumeDataSet_T1_7.csv', feature_name='Resume')\n",
    "processed_resumes['Resume'][2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.406961100Z",
     "start_time": "2024-01-28T16:54:59.701596400Z"
    }
   },
   "id": "2b9992be2a73bbda",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Java Developer               14\n",
      "Data Science                 12\n",
      "HR                           12\n",
      "Database                     11\n",
      "Advocate                     10\n",
      "DotNet Developer              8\n",
      "Hadoop                        8\n",
      "DevOps Engineer               8\n",
      "Business Analyst              8\n",
      "Testing                       8\n",
      "Civil Engineer                7\n",
      "SAP Developer                 7\n",
      "Health and fitness            7\n",
      "Python Developer              7\n",
      "Arts                          7\n",
      "Automation Testing            7\n",
      "Electrical Engineering        6\n",
      "Sales                         6\n",
      "Network Security Engineer     6\n",
      "ETL Developer                 6\n",
      "Mechanical Engineer           5\n",
      "Web Designing                 5\n",
      "Blockchain                    5\n",
      "Operations Manager            4\n",
      "PMO                           4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(processed_resumes['Category'].value_counts()) # Require at least 7 per class for trainTestSplit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.411920Z",
     "start_time": "2024-01-28T16:55:02.407964200Z"
    }
   },
   "id": "57e7cd8148599e83",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              Category                                             Resume\n0         Data Science  qwtnrvduof education detail may 2013 to may 20...\n1         Data Science  qwtnrvduof area of interest deep learn control...\n2         Data Science  skill r python sap hana tableau sap hana sql s...\n3         Data Science  education detail mca ymcaust faridabad haryana...\n4         Data Science  skill c basic iot python matlab data science m...\n...                ...                                                ...\n873            Testing  skill set o window xp 7 8 8bntgbqlmkk1 10 data...\n874            Testing  good logical and analytical skill positive att...\n878            Testing  personal skill quick learner eagerness to lear...\n1540   DevOps Engineer  core skill project program management agile sc...\n7135  Business Analyst  education detail february 2006 to february 200...\n\n[188 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Resume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Science</td>\n      <td>qwtnrvduof education detail may 2013 to may 20...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Science</td>\n      <td>qwtnrvduof area of interest deep learn control...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Data Science</td>\n      <td>skill r python sap hana tableau sap hana sql s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Data Science</td>\n      <td>education detail mca ymcaust faridabad haryana...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Data Science</td>\n      <td>skill c basic iot python matlab data science m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>873</th>\n      <td>Testing</td>\n      <td>skill set o window xp 7 8 8bntgbqlmkk1 10 data...</td>\n    </tr>\n    <tr>\n      <th>874</th>\n      <td>Testing</td>\n      <td>good logical and analytical skill positive att...</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>Testing</td>\n      <td>personal skill quick learner eagerness to lear...</td>\n    </tr>\n    <tr>\n      <th>1540</th>\n      <td>DevOps Engineer</td>\n      <td>core skill project program management agile sc...</td>\n    </tr>\n    <tr>\n      <th>7135</th>\n      <td>Business Analyst</td>\n      <td>education detail february 2006 to february 200...</td>\n    </tr>\n  </tbody>\n</table>\n<p>188 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_resumes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.420954700Z",
     "start_time": "2024-01-28T16:55:02.410920300Z"
    }
   },
   "id": "41d01493dffd013f",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "minimum = 7\n",
    "current_lowest = processed_resumes['Category'].value_counts().min()\n",
    "\n",
    "#Check\n",
    "count = processed_resumes['Category'].value_counts()\n",
    "remaining = 7 - count[count<minimum]\n",
    "\n",
    "while len(remaining != 0):\n",
    "    count = processed_resumes['Category'].value_counts()\n",
    "    remaining = 7 - count[count<minimum]\n",
    "    \n",
    "    for category in remaining.index:\n",
    "        someInt = random.randint(0, current_lowest-1)\n",
    "        value_to_append = processed_resumes[\n",
    "            processed_resumes['Category']==category\n",
    "        ]['Resume'].values[someInt]\n",
    "        \n",
    "        \n",
    "        df_to_concat = pd.DataFrame({\n",
    "            'Category': [category],\n",
    "            'Resume': [value_to_append]\n",
    "        })\n",
    "    \n",
    "        processed_resumes = pd.concat([processed_resumes, df_to_concat], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.452721500Z",
     "start_time": "2024-01-28T16:55:02.426017100Z"
    }
   },
   "id": "768fe0dfcf7e9c7b",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Task: Initiating Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "630f146353fd6177"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_class_labels(labels: Iterable):\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    \n",
    "    unique_labels_map = {}\n",
    "    \n",
    "    for index, label in enumerate(unique_labels, start=0):\n",
    "        unique_labels_map[label] = index\n",
    "        \n",
    "    return unique_labels_map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.453720400Z",
     "start_time": "2024-01-28T16:55:02.428524400Z"
    }
   },
   "id": "d20df1d44660606c",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels, features = processed_resumes['Category'], \\\n",
    "    processed_resumes['Resume'].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.453720400Z",
     "start_time": "2024-01-28T16:55:02.431711500Z"
    }
   },
   "id": "3e17cdfadd53c3db",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label_map = generate_class_labels(labels)\n",
    "\n",
    "labels = labels.apply(lambda label_name: label_map[label_name])\n",
    "\n",
    "labels = labels.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:02.454719900Z",
     "start_time": "2024-01-28T16:55:02.434738500Z"
    }
   },
   "id": "36583014b2b89e52",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JS\\anaconda3\\envs\\NLPProjectVenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from transformers import AdamW"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:06.507295600Z",
     "start_time": "2024-01-28T16:55:02.438214100Z"
    }
   },
   "id": "660a1849204e3fbe",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:06.526893Z",
     "start_time": "2024-01-28T16:55:06.508296100Z"
    }
   },
   "id": "8f482b5f4916692",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_resumes = [tokenizer.tokenize(feature) for feature in features]\n",
    "\n",
    "assert len(tokenized_resumes) == processed_resumes.Resume.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.689316400Z",
     "start_time": "2024-01-28T16:55:06.530774700Z"
    }
   },
   "id": "c225f50156c2b7f",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for tokenized_resume in tokenized_resumes:\n",
    "    if len(tokenized_resume) > max_len:\n",
    "        max_len = len(tokenized_resume)\n",
    "    else:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.700447800Z",
     "start_time": "2024-01-28T16:55:07.690315600Z"
    }
   },
   "id": "842690413022151c",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_len = 512 # TODO DELETE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.701448100Z",
     "start_time": "2024-01-28T16:55:07.692709400Z"
    }
   },
   "id": "1cea9117dad1acec",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_ids = [\n",
    "    tokenizer.convert_tokens_to_ids(tokenized_resume) for tokenized_resume in tokenized_resumes\n",
    "]\n",
    "\n",
    "assert len(input_ids[0]) == len(tokenized_resumes[0])\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', truncating='post', padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.728461400Z",
     "start_time": "2024-01-28T16:55:07.696448400Z"
    }
   },
   "id": "7cf87b4f2556b8e2",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "attention_masks_ = []\n",
    "for resume_id in input_ids:\n",
    "    resume_mask = [float(id > 0) for id in resume_id]\n",
    "    attention_masks_.append(resume_mask)\n",
    "    \n",
    "assert len(attention_masks_[0]) == max_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.748034300Z",
     "start_time": "2024-01-28T16:55:07.729462Z"
    }
   },
   "id": "886695c81e10e492",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train, x_test_and_val, y_train, y_test_and_val, z_train, z_test_and_val = train_test_split(\n",
    "    input_ids, labels, attention_masks_, test_size=0.3, stratify=labels\n",
    ")\n",
    "\n",
    "x_val, x_test, y_val, y_test, z_val, z_test = train_test_split(\n",
    "    x_test_and_val, y_test_and_val, z_test_and_val, test_size=0.5, stratify=y_test_and_val\n",
    ")\n",
    "\n",
    "assert x_train.shape[0] == y_train.shape[0] == len(z_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.756229100Z",
     "start_time": "2024-01-28T16:55:07.749034800Z"
    }
   },
   "id": "c9805c51d07aaa84",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data = TensorDataset(torch.tensor(x_train), torch.tensor(z_train), torch.tensor(y_train))\n",
    "training_sampler = RandomSampler(training_data)\n",
    "training_dataloader = DataLoader(training_data, sampler=training_sampler, batch_size=VAR['batch_size'])\n",
    "\n",
    "validation_data = TensorDataset(\n",
    "    torch.tensor(x_val),\n",
    "    torch.tensor(z_val),\n",
    "    torch.tensor(y_val)\n",
    ")\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=VAR['batch_size']\n",
    ")\n",
    "\n",
    "prediction_data = TensorDataset(torch.tensor(x_test), torch.tensor(z_test), torch.tensor(y_test))\n",
    "prediction_dataloader = DataLoader(prediction_data, batch_size=VAR['batch_size'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:07.768301700Z",
     "start_time": "2024-01-28T16:55:07.756229100Z"
    }
   },
   "id": "bf1779bafc385f27",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Task: Initiating Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd49838fc1356"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "configuration = BertConfig()\n",
    "model = BertModel(configuration)\n",
    "configuration = model.config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:08.693018700Z",
     "start_time": "2024-01-28T16:55:07.769302Z"
    }
   },
   "id": "ae9f98640bad620b",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    num_labels=len(label_map.keys())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:09.371007500Z",
     "start_time": "2024-01-28T16:55:08.694019100Z"
    }
   },
   "id": "af076dd8fa79d392",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DataParallel(\n  (module): BertForSequenceClassification(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (classifier): Linear(in_features=768, out_features=25, bias=True)\n  )\n)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:09.492981800Z",
     "start_time": "2024-01-28T16:55:09.372009900Z"
    }
   },
   "id": "5dac53bfc3d53bb3",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\anaconda3\\envs\\NLPProjectVenv\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [\n",
    "        p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "    ], 'weight_decay': 0.01},\n",
    "    {'params': [\n",
    "        p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "    ], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, correct_bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:09.667465200Z",
     "start_time": "2024-01-28T16:55:09.493983300Z"
    }
   },
   "id": "fbb277e3e0ef2203",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, labels):\n",
    "    predicted_labels = np.argmax(predicted_labels.to('cpu').numpy(), axis=1).flatten()\n",
    "    labels = labels.to('cpu').numpy().flatten()\n",
    "    \n",
    "    return np.sum(predicted_labels == labels) / len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:09.669744400Z",
     "start_time": "2024-01-28T16:55:09.667465200Z"
    }
   },
   "id": "ae6e629d0c305872",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "epochs = 4\n",
    "training_losses = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T16:55:09.674825400Z",
     "start_time": "2024-01-28T16:55:09.670744300Z"
    }
   },
   "id": "7650f1b6fd353990",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.6286, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.8454,  2.2061,  0.7433,  1.0613,  1.5283,  2.0653, -0.1181,  1.8412,\n",
      "          2.9870,  0.6270,  1.2781, -0.0305,  2.2433,  1.7404,  0.2673, -0.2461,\n",
      "          1.6554,  1.8461,  1.9245,  2.2585,  2.5418,  1.1703,  2.2930,  1.3119,\n",
      "          0.1057],\n",
      "        [ 1.2418,  2.6880,  0.9460,  2.4484,  2.6387,  2.4543,  0.7652,  2.1591,\n",
      "          2.6499,  0.9125,  1.1700,  0.4812,  2.0098,  1.7857,  0.3272,  0.3090,\n",
      "          0.4598,  1.0582,  2.2957,  2.6767,  2.4618,  1.5082,  2.0762,  1.7423,\n",
      "          0.6134],\n",
      "        [ 1.7983,  2.2307,  1.1898,  1.5823,  2.5781,  2.2608,  0.5176,  2.1165,\n",
      "          2.7798,  0.9782,  1.2781, -0.2517,  2.0461,  1.5560,  0.4805, -0.1195,\n",
      "          0.9486,  1.3750,  2.3641,  2.6312,  2.4572,  1.5764,  2.2369,  1.5507,\n",
      "         -0.0477],\n",
      "        [ 2.0439,  2.7796,  0.6249,  1.2962,  1.8488,  2.5226,  0.5939,  2.2615,\n",
      "          2.7694,  1.4002,  1.6559, -0.1352,  2.2758,  1.2494,  0.3829, -0.3317,\n",
      "          0.9523,  1.9862,  2.1033,  2.2216,  2.4621,  1.7065,  2.5379,  2.0467,\n",
      "          0.1891],\n",
      "        [ 1.7093,  2.5122,  0.9268,  1.4392,  2.5860,  2.1398,  0.2659,  1.9562,\n",
      "          3.0098,  1.1348,  1.4546, -0.0928,  2.3418,  1.3663,  0.2991,  0.1359,\n",
      "          0.8074,  1.4508,  2.3641,  2.7104,  1.9954,  1.0842,  2.3027,  1.5887,\n",
      "          0.3872],\n",
      "        [ 1.8042,  2.7695,  0.8782,  1.2135,  2.7001,  2.1289,  0.8606,  1.7628,\n",
      "          2.6017,  0.8682,  1.5317,  0.1731,  2.5612,  1.5520,  0.3394,  0.0588,\n",
      "          0.5195,  1.4746,  2.0598,  2.5567,  2.6829,  1.5513,  2.2888,  1.7958,\n",
      "          0.6092],\n",
      "        [ 1.7697,  2.4270,  0.6312,  1.5191,  2.4348,  2.2711,  0.7578,  1.9797,\n",
      "          2.2385,  0.4644,  1.1796, -0.1049,  2.3835,  1.6795,  0.2325,  0.1047,\n",
      "          1.4397,  1.3653,  2.4569,  2.7850,  2.7797,  1.3525,  1.9947,  1.3680,\n",
      "          0.1517],\n",
      "        [ 1.9577,  2.5357,  0.5739,  1.6532,  2.6149,  2.5399,  0.3050,  1.8228,\n",
      "          2.7854,  0.5171,  1.0536,  0.1200,  2.0738,  1.8496,  0.3854, -0.0317,\n",
      "          0.7823,  1.5448,  2.2190,  2.3331,  2.3960,  1.6543,  2.4004,  1.5868,\n",
      "          0.3913],\n",
      "        [ 1.6330,  2.7812,  0.8608,  1.3494,  2.8866,  2.3140,  0.1775,  2.1872,\n",
      "          3.0376,  1.0374,  1.4055, -0.0520,  2.2391,  1.8097,  0.4509, -0.0456,\n",
      "          0.3529,  1.5524,  2.4474,  2.7860,  2.3517,  2.2042,  2.5421,  2.0504,\n",
      "          0.1623],\n",
      "        [ 1.7138,  2.6006,  1.5423,  1.0938,  2.1486,  1.6656,  0.6459,  2.5713,\n",
      "          2.5783,  0.6025,  1.5152,  0.2262,  1.8551,  1.7011, -0.1944, -0.5722,\n",
      "          1.3193,  1.5966,  2.5222,  1.9416,  2.7060,  1.6534,  1.9995,  1.2919,\n",
      "          0.3352],\n",
      "        [ 1.7150,  2.8654,  1.1217,  1.2747,  2.9170,  2.2351,  0.3382,  2.4740,\n",
      "          3.2141,  1.4421,  1.2119,  0.1248,  2.2651,  1.4697,  0.4547,  0.0882,\n",
      "          0.7730,  1.7861,  2.6036,  2.9023,  2.2317,  1.7099,  2.2184,  2.3892,\n",
      "          0.1978],\n",
      "        [ 1.7798,  2.7309,  1.0090,  1.3176,  2.7993,  2.3070,  0.5332,  2.1648,\n",
      "          2.6726,  1.1894,  1.0516, -0.0465,  2.2285,  1.5978,  0.2222,  0.0581,\n",
      "          0.4714,  1.7934,  2.2939,  2.9990,  2.4222,  1.8028,  2.4095,  1.9130,\n",
      "          0.4408],\n",
      "        [ 1.8730,  2.4107,  1.0218,  1.6120,  2.7240,  1.9219,  0.3012,  1.8444,\n",
      "          2.8537,  0.8811,  0.7875, -0.0384,  2.3908,  1.5994,  0.0684, -0.1340,\n",
      "          0.8442,  1.1949,  2.6220,  2.3241,  1.8869,  1.2650,  1.9323,  1.2341,\n",
      "          0.3825],\n",
      "        [ 1.5149,  2.6572,  0.9819,  1.1776,  2.6457,  2.9103,  0.4629,  2.0577,\n",
      "          2.7626,  0.8777,  1.1651,  0.3085,  2.5139,  1.6528,  0.6208,  0.0993,\n",
      "          0.2455,  1.1979,  2.5455,  2.1675,  2.6461,  1.7681,  2.6180,  1.8920,\n",
      "          0.2185],\n",
      "        [ 1.9629,  3.0608,  0.8185,  1.3308,  2.5307,  1.9514,  0.0614,  2.6261,\n",
      "          2.6972,  0.8183,  1.3179,  0.4820,  2.1404,  1.6463,  0.3454, -0.4184,\n",
      "          1.0829,  1.4488,  2.2867,  2.8224,  2.2544,  1.7505,  1.8231,  1.6690,\n",
      "          0.1352],\n",
      "        [ 1.5596,  2.5448,  0.7223,  1.4689,  2.3961,  2.4269,  0.4406,  2.0021,\n",
      "          2.8268,  0.8491,  1.1026,  0.3129,  1.8024,  1.8785,  0.4317, -0.2190,\n",
      "          0.8412,  1.2498,  3.1321,  2.2418,  2.3037,  1.3554,  2.2744,  1.7301,\n",
      "          0.0046],\n",
      "        [ 1.5837,  2.8637,  0.8583,  1.4256,  2.5749,  2.8551,  0.3058,  2.1096,\n",
      "          2.9832,  1.0274,  0.8419, -0.2572,  2.4016,  1.4901,  0.5700, -0.0789,\n",
      "          0.2530,  1.2143,  2.5406,  2.9135,  2.5517,  1.5899,  1.8745,  2.1838,\n",
      "          0.6509],\n",
      "        [ 1.4314,  2.4664,  0.9688,  1.3877,  2.9754,  2.9499,  0.5188,  1.7571,\n",
      "          2.9574,  1.5230,  0.9347, -0.0074,  2.2231,  1.3982,  0.5500,  0.3693,\n",
      "          0.8877,  1.1335,  1.5934,  2.8584,  2.3170,  1.7738,  2.2959,  1.6748,\n",
      "          0.1666],\n",
      "        [ 2.0254,  2.7421,  1.1405,  0.8677,  2.2897,  1.9761,  0.2025,  1.8435,\n",
      "          2.8004,  1.1344,  1.4815,  0.1095,  2.1791,  1.9767,  0.3483, -0.1740,\n",
      "          0.6446,  1.2371,  2.2542,  2.7270,  2.1081,  1.4114,  1.8942,  1.5054,\n",
      "          0.3710],\n",
      "        [ 1.8351,  2.6577,  0.9162,  1.6583,  2.8016,  2.1314,  0.7272,  1.9281,\n",
      "          2.6210,  0.9355,  0.9411, -0.1629,  2.3173,  1.4600,  0.4912, -0.1546,\n",
      "          0.5777,  1.4430,  2.5270,  2.6267,  2.3103,  1.4806,  2.2927,  1.8935,\n",
      "          0.1888],\n",
      "        [ 1.8693,  2.2619,  1.0357,  1.3940,  2.4845,  1.9435,  0.6908,  2.1899,\n",
      "          2.9929,  1.0823,  1.2090, -0.3721,  2.4646,  1.3857, -0.0422,  0.1638,\n",
      "          0.7045,  1.7439,  2.5298,  2.7185,  2.3326,  1.6452,  2.0690,  1.9345,\n",
      "          0.1975],\n",
      "        [ 1.7303,  2.7524,  0.7664,  1.8244,  2.9637,  2.2507,  0.5534,  1.8185,\n",
      "          3.2836,  0.8426,  1.2806, -0.1240,  2.2610,  1.9763,  0.4438,  0.1876,\n",
      "          0.8036,  1.3183,  2.1910,  2.3444,  2.5472,  1.4818,  2.1400,  1.6310,\n",
      "          0.3038],\n",
      "        [ 1.4610,  2.5649,  1.0234,  1.1041,  2.9522,  2.2746, -0.0405,  2.2899,\n",
      "          2.9653,  1.0300,  0.9928, -0.3501,  2.6198,  2.0963,  0.3220, -0.0470,\n",
      "          1.1120,  1.3347,  2.6344,  2.1366,  2.3878,  1.4720,  2.0978,  1.3069,\n",
      "          0.1225],\n",
      "        [ 1.9106,  2.3538,  0.9314,  1.1755,  2.3215,  2.4265,  0.4943,  2.3366,\n",
      "          2.8584,  1.0308,  1.0772, -0.0835,  2.1627,  1.6266,  0.7212, -0.0591,\n",
      "          0.7800,  1.7711,  2.1728,  2.6131,  2.6142,  1.6560,  2.4485,  1.4838,\n",
      "          0.2961],\n",
      "        [ 2.0085,  2.4925,  0.8711,  1.2446,  2.9585,  2.0538,  0.6402,  2.2216,\n",
      "          2.7890,  0.6670,  1.4699, -0.3101,  2.2961,  1.6597,  0.2014, -0.1604,\n",
      "          0.7795,  1.1149,  2.5469,  2.1825,  2.3927,  1.7886,  2.2372,  1.3464,\n",
      "          0.3205],\n",
      "        [ 2.0787,  2.5321,  0.7242,  0.8148,  2.2577,  2.0924,  0.1225,  2.0236,\n",
      "          2.7060,  1.0966,  1.1338,  0.2586,  1.9025,  1.8776,  0.2517, -0.2768,\n",
      "          1.0642,  1.6295,  2.4009,  2.8780,  2.3797,  1.6711,  1.8122,  1.7551,\n",
      "          0.3296],\n",
      "        [ 1.6649,  2.8441,  0.9873,  1.2661,  2.4017,  1.5582,  0.4827,  1.7350,\n",
      "          2.5886,  1.4221,  1.1401,  0.0171,  1.7678,  1.4976,  0.1846, -0.2323,\n",
      "          1.4127,  1.5640,  2.5058,  2.5634,  2.6997,  1.4878,  2.1780,  1.3877,\n",
      "          0.0818],\n",
      "        [ 1.8116,  2.9165,  0.9988,  1.5895,  2.5839,  2.4565,  0.2227,  2.2798,\n",
      "          2.8194,  1.4461,  1.2726,  0.2278,  1.9352,  1.6948,  0.3082, -0.1914,\n",
      "          1.2188,  1.6595,  2.2629,  2.3696,  2.4462,  1.5362,  1.8549,  1.6395,\n",
      "          0.0834],\n",
      "        [ 2.0041,  2.6058,  1.3653,  1.4696,  2.6529,  2.2226,  0.4745,  1.7624,\n",
      "          2.7338,  1.1413,  1.6410,  0.3848,  2.0879,  1.5451,  0.0394,  0.0380,\n",
      "          0.5509,  1.8145,  2.0206,  3.0313,  2.0210,  1.7032,  1.8428,  1.8158,\n",
      "          0.0845],\n",
      "        [ 1.5661,  2.5110,  1.0086,  1.1026,  2.8800,  2.1387,  0.3539,  2.3759,\n",
      "          2.7405,  0.6788,  1.1348, -0.2488,  2.2528,  1.5954,  0.0669, -0.1969,\n",
      "          1.1254,  1.0767,  2.5169,  2.8870,  2.1080,  1.4711,  2.1077,  1.7322,\n",
      "          0.3284],\n",
      "        [ 1.6492,  2.7659,  1.2258,  1.4335,  2.1570,  2.0843,  0.6700,  2.1314,\n",
      "          2.4934,  1.2772,  1.6827,  0.0332,  2.1195,  1.7461,  0.2409, -0.3452,\n",
      "          1.1616,  1.9356,  2.2241,  2.5305,  2.1243,  1.7346,  2.0406,  1.6922,\n",
      "         -0.0608],\n",
      "        [ 1.9759,  2.9931,  1.0359,  0.7065,  2.6287,  2.5875, -0.0254,  2.1592,\n",
      "          2.6048,  0.9408,  1.3763,  0.1053,  1.8080,  1.6054,  0.3942, -0.4297,\n",
      "          0.7170,  1.1999,  2.2824,  2.1221,  2.7037,  1.5784,  2.4351,  1.1479,\n",
      "          0.6166]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.5249, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.5003e+00,  2.6714e+00,  1.6342e+00,  5.3183e-01,  2.1250e+00,\n",
      "          1.7811e+00,  1.2181e+00,  2.4953e+00,  2.2401e+00,  1.9445e+00,\n",
      "          8.3915e-01, -1.0101e+00,  2.3606e+00,  1.0084e+00,  2.1654e-01,\n",
      "          3.6852e-01,  1.3590e+00,  1.6779e+00,  1.3422e+00,  1.7155e+00,\n",
      "          2.7288e+00,  1.0202e+00,  2.6942e+00,  1.5023e+00,  3.4886e-01],\n",
      "        [ 1.1592e+00,  2.5775e+00,  1.6680e+00,  4.9101e-01,  2.5662e+00,\n",
      "          1.7778e+00,  1.0242e+00,  2.0403e+00,  2.3561e+00,  1.5888e+00,\n",
      "          1.2147e+00, -1.0616e+00,  2.4618e+00,  1.3947e+00,  3.7280e-01,\n",
      "         -2.3890e-01,  1.1395e+00,  1.0721e+00,  1.9431e+00,  1.3416e+00,\n",
      "          2.2310e+00,  9.9111e-01,  2.8110e+00,  9.7285e-01, -1.0661e-01],\n",
      "        [ 1.4479e+00,  3.2422e+00,  1.8477e+00,  6.8930e-01,  2.6127e+00,\n",
      "          2.0085e+00,  1.3851e+00,  2.4991e+00,  2.5172e+00,  1.8571e+00,\n",
      "          1.3205e+00, -2.5557e-01,  2.9199e+00,  1.5617e+00,  2.3369e-02,\n",
      "          5.7949e-01,  1.2536e+00,  1.2171e+00,  1.4395e+00,  2.3689e+00,\n",
      "          2.5371e+00,  7.2737e-01,  2.4962e+00,  1.5813e+00,  6.8606e-02],\n",
      "        [ 5.9950e-01,  2.6482e+00,  1.3698e+00,  1.1947e+00,  3.2887e+00,\n",
      "          1.4164e+00,  1.7091e+00,  2.5003e+00,  1.9502e+00,  1.2315e+00,\n",
      "          9.2410e-01, -1.0961e+00,  2.6564e+00,  1.6746e+00,  1.3733e-01,\n",
      "          1.2721e-01,  9.2693e-01,  6.0231e-01,  1.9475e+00,  2.1110e+00,\n",
      "          2.5133e+00,  9.0249e-01,  2.9515e+00,  1.3709e+00,  3.7032e-01],\n",
      "        [ 1.4476e+00,  2.8940e+00,  1.3875e+00,  7.3623e-01,  2.9829e+00,\n",
      "          1.5228e+00,  1.3012e+00,  2.4420e+00,  1.6974e+00,  1.6697e+00,\n",
      "          1.3921e+00, -1.3781e+00,  2.4469e+00,  1.7312e+00,  3.2554e-01,\n",
      "         -2.5375e-01,  1.0516e+00,  1.5768e+00,  1.9323e+00,  1.1226e+00,\n",
      "          2.4377e+00,  1.5597e+00,  3.3885e+00,  1.6615e+00,  2.1174e-01],\n",
      "        [ 1.0794e+00,  2.8238e+00,  1.3492e+00,  1.1501e+00,  2.8586e+00,\n",
      "          1.6985e+00,  1.7289e+00,  2.1588e+00,  2.3715e+00,  1.8507e+00,\n",
      "          1.3644e+00, -1.2060e+00,  2.5784e+00,  1.2585e+00,  1.3530e-01,\n",
      "          2.9809e-01,  4.9831e-01,  9.2085e-01,  1.6040e+00,  2.2192e+00,\n",
      "          1.7773e+00,  8.8716e-01,  2.8370e+00,  1.6972e+00,  4.4641e-01],\n",
      "        [ 1.0800e+00,  3.0982e+00,  1.6369e+00,  1.0491e+00,  2.4772e+00,\n",
      "          1.6535e+00,  1.1608e+00,  2.3897e+00,  2.0420e+00,  1.5294e+00,\n",
      "          4.9741e-01, -8.8379e-01,  2.6056e+00,  1.6510e+00,  3.0697e-01,\n",
      "          5.1683e-01,  7.6358e-01,  1.2232e+00,  2.2765e+00,  2.0650e+00,\n",
      "          2.2167e+00,  7.5205e-01,  2.8904e+00,  1.6563e+00, -9.1575e-02],\n",
      "        [ 1.0240e+00,  3.2928e+00,  1.2439e+00,  1.4915e+00,  2.8869e+00,\n",
      "          1.7967e+00,  1.2288e+00,  2.9250e+00,  2.6222e+00,  2.4897e+00,\n",
      "          7.9336e-01, -3.3375e-01,  2.6280e+00,  1.5784e+00,  4.9369e-01,\n",
      "          4.0244e-01,  3.5937e-01,  1.0692e+00,  1.8202e+00,  1.7391e+00,\n",
      "          2.1853e+00,  5.6662e-01,  2.9795e+00,  2.0046e+00, -9.0538e-02],\n",
      "        [ 1.3153e+00,  2.5946e+00,  1.6031e+00,  4.1735e-01,  2.7147e+00,\n",
      "          1.5899e+00,  1.4230e+00,  2.5219e+00,  2.5426e+00,  2.3429e+00,\n",
      "          1.3938e+00, -1.2444e+00,  2.6187e+00,  1.4838e+00,  2.2897e-01,\n",
      "          9.9710e-02,  1.3175e+00,  1.3556e+00,  1.8631e+00,  1.8649e+00,\n",
      "          2.2548e+00,  1.2979e+00,  3.1492e+00,  1.4954e+00, -3.0429e-02],\n",
      "        [ 1.4425e+00,  2.8816e+00,  1.5577e+00,  1.1992e+00,  3.0612e+00,\n",
      "          1.5190e+00,  1.3712e+00,  2.3946e+00,  2.3662e+00,  1.8312e+00,\n",
      "          7.6137e-01, -4.2801e-01,  2.7782e+00,  1.9583e+00,  3.0510e-02,\n",
      "          4.9352e-01,  6.1774e-01,  1.1664e+00,  1.5266e+00,  1.9789e+00,\n",
      "          2.6121e+00,  5.6016e-01,  2.8516e+00,  1.6041e+00,  1.3094e-01],\n",
      "        [ 1.1566e+00,  2.8562e+00,  1.2898e+00,  1.5635e+00,  3.3690e+00,\n",
      "          1.8766e+00,  1.4826e+00,  2.4745e+00,  2.1471e+00,  2.1238e+00,\n",
      "          1.2598e+00, -7.6500e-01,  2.4619e+00,  2.0212e+00,  5.3497e-01,\n",
      "          6.3633e-01,  7.3240e-01,  9.3318e-01,  2.0555e+00,  2.1663e+00,\n",
      "          2.6820e+00,  1.0067e+00,  2.6014e+00,  1.6458e+00,  5.7309e-01],\n",
      "        [ 1.3509e+00,  2.8953e+00,  1.6654e+00,  1.1006e+00,  2.5944e+00,\n",
      "          1.9724e+00,  1.2306e+00,  2.7343e+00,  2.2609e+00,  2.1831e+00,\n",
      "          8.2616e-01, -7.9448e-01,  2.3498e+00,  1.7632e+00,  2.1490e-01,\n",
      "          3.2386e-01,  1.0750e+00,  8.5179e-01,  1.8063e+00,  1.6465e+00,\n",
      "          2.3861e+00,  9.6141e-01,  2.8689e+00,  1.5534e+00,  1.2643e-01],\n",
      "        [ 1.1786e+00,  2.6597e+00,  1.7640e+00,  8.3278e-01,  2.8658e+00,\n",
      "          1.6645e+00,  1.1474e+00,  2.0111e+00,  1.9809e+00,  1.7010e+00,\n",
      "          7.8253e-01, -1.0956e+00,  2.4642e+00,  1.6490e+00,  3.5717e-01,\n",
      "          2.8795e-01,  8.4763e-01,  8.7788e-01,  1.5843e+00,  1.8207e+00,\n",
      "          2.6225e+00,  8.0787e-01,  3.2950e+00,  1.4702e+00,  6.7314e-02],\n",
      "        [ 1.0328e+00,  2.9425e+00,  1.6925e+00,  5.1748e-01,  2.5985e+00,\n",
      "          1.8060e+00,  8.8193e-01,  2.2115e+00,  2.3722e+00,  1.8340e+00,\n",
      "          1.4001e+00, -1.2613e+00,  2.5390e+00,  1.2738e+00,  6.4686e-01,\n",
      "          1.7548e-01,  1.0785e+00,  1.2667e+00,  1.6716e+00,  1.8540e+00,\n",
      "          2.8810e+00,  7.9071e-01,  3.4590e+00,  1.1466e+00,  1.7687e-01],\n",
      "        [ 1.5613e+00,  2.8277e+00,  1.6225e+00,  5.4417e-01,  2.3195e+00,\n",
      "          1.7915e+00,  1.2261e+00,  2.4262e+00,  2.0353e+00,  2.2232e+00,\n",
      "          1.2119e+00, -8.4692e-01,  2.6827e+00,  1.7824e+00,  3.6425e-01,\n",
      "          2.4348e-01,  9.3738e-01,  1.1013e+00,  2.0554e+00,  1.9298e+00,\n",
      "          2.2372e+00,  9.1255e-01,  2.8862e+00,  1.8119e+00, -3.2037e-01],\n",
      "        [ 1.5746e+00,  2.9601e+00,  1.3619e+00,  1.1517e+00,  2.7422e+00,\n",
      "          1.8939e+00,  1.0419e+00,  2.5336e+00,  1.7396e+00,  1.9398e+00,\n",
      "          1.1882e+00, -7.0946e-01,  2.4152e+00,  1.5106e+00,  3.0703e-01,\n",
      "         -1.0591e-03,  1.1583e+00,  1.4869e+00,  1.9053e+00,  1.6517e+00,\n",
      "          2.3278e+00,  6.3624e-01,  2.9389e+00,  1.3511e+00,  2.3045e-01],\n",
      "        [ 1.3650e+00,  3.2029e+00,  1.3150e+00,  8.7814e-01,  3.1585e+00,\n",
      "          2.0556e+00,  1.3079e+00,  2.6163e+00,  2.3889e+00,  2.3153e+00,\n",
      "          8.6445e-01, -9.0410e-01,  2.4813e+00,  1.8143e+00,  4.0131e-01,\n",
      "          4.5778e-01,  6.4640e-01,  1.0961e+00,  1.5719e+00,  2.3094e+00,\n",
      "          2.5546e+00,  1.0387e+00,  2.7739e+00,  1.5878e+00,  4.7464e-01],\n",
      "        [ 1.2695e+00,  2.3958e+00,  1.3762e+00,  1.4527e+00,  3.0255e+00,\n",
      "          1.9593e+00,  1.4394e+00,  2.4629e+00,  2.4592e+00,  1.8418e+00,\n",
      "          1.0484e+00, -1.0357e+00,  2.3921e+00,  1.6713e+00,  3.9892e-01,\n",
      "          4.6403e-01,  6.0163e-01,  7.8390e-01,  1.6800e+00,  1.5880e+00,\n",
      "          2.5893e+00,  7.2510e-01,  3.0757e+00,  1.5441e+00,  1.6808e-01],\n",
      "        [ 9.3902e-01,  2.9451e+00,  1.7028e+00,  9.7525e-01,  2.6796e+00,\n",
      "          2.1427e+00,  1.5114e+00,  2.2867e+00,  1.9141e+00,  1.8800e+00,\n",
      "          1.1880e+00, -1.0833e+00,  2.2904e+00,  1.6216e+00,  2.5185e-01,\n",
      "          4.3045e-01,  8.2099e-01,  1.5559e+00,  1.6529e+00,  1.8002e+00,\n",
      "          2.4473e+00,  1.1924e+00,  2.9851e+00,  1.2623e+00,  3.4797e-01],\n",
      "        [ 1.4014e+00,  2.7113e+00,  1.8370e+00,  1.0403e+00,  2.3785e+00,\n",
      "          1.7053e+00,  1.3619e+00,  2.7314e+00,  1.9162e+00,  2.1208e+00,\n",
      "          1.1315e+00, -7.7104e-01,  2.2230e+00,  1.7432e+00,  3.4820e-01,\n",
      "         -2.3619e-01,  1.2132e+00,  1.5978e+00,  1.6574e+00,  1.6209e+00,\n",
      "          2.0695e+00,  1.1967e+00,  2.8400e+00,  1.6447e+00, -2.7283e-01],\n",
      "        [ 1.3342e+00,  2.8422e+00,  1.7363e+00,  7.7837e-01,  2.5152e+00,\n",
      "          1.4570e+00,  1.1304e+00,  2.4864e+00,  2.1356e+00,  1.7083e+00,\n",
      "          1.2323e+00, -4.3936e-01,  2.6172e+00,  1.5081e+00,  5.1767e-01,\n",
      "          1.3737e-01,  1.1815e+00,  1.4611e+00,  1.8923e+00,  2.1337e+00,\n",
      "          2.2442e+00,  9.9456e-01,  2.6444e+00,  1.6445e+00, -6.4869e-02],\n",
      "        [ 1.7380e+00,  2.9025e+00,  1.7029e+00,  7.9530e-01,  2.4411e+00,\n",
      "          1.4539e+00,  1.0410e+00,  2.5641e+00,  1.7221e+00,  2.0098e+00,\n",
      "          1.4135e+00, -5.7605e-01,  2.2432e+00,  1.9189e+00,  9.1602e-02,\n",
      "         -1.0433e-01,  1.3045e+00,  1.6483e+00,  1.6248e+00,  1.8727e+00,\n",
      "          2.0433e+00,  8.6765e-01,  2.8690e+00,  1.6746e+00, -7.8738e-02],\n",
      "        [ 1.5486e+00,  2.6047e+00,  1.3966e+00,  1.0224e+00,  2.2942e+00,\n",
      "          1.6079e+00,  1.0261e+00,  2.0643e+00,  2.0607e+00,  1.4713e+00,\n",
      "          1.2876e+00, -6.4545e-01,  2.4399e+00,  1.7151e+00,  2.2745e-02,\n",
      "          3.8517e-01,  7.2685e-01,  1.0908e+00,  1.2625e+00,  2.1482e+00,\n",
      "          2.6613e+00,  8.2967e-01,  2.9138e+00,  1.6696e+00,  2.6392e-01],\n",
      "        [ 8.8354e-01,  2.8105e+00,  1.7573e+00,  1.0108e+00,  3.2555e+00,\n",
      "          1.9819e+00,  1.1791e+00,  2.3591e+00,  2.3229e+00,  1.8674e+00,\n",
      "          1.2958e+00, -9.2757e-01,  2.7271e+00,  1.5298e+00,  1.2304e-01,\n",
      "          4.5595e-01,  8.4925e-01,  4.5196e-01,  1.8452e+00,  1.5435e+00,\n",
      "          2.8303e+00,  7.7312e-01,  3.2665e+00,  1.2246e+00,  6.2729e-02],\n",
      "        [ 1.1669e+00,  2.8576e+00,  1.8481e+00,  7.9092e-01,  2.7832e+00,\n",
      "          1.6262e+00,  1.3504e+00,  2.6406e+00,  1.8822e+00,  1.6934e+00,\n",
      "          8.3892e-01, -1.1639e+00,  2.7829e+00,  1.8522e+00,  3.1642e-01,\n",
      "          2.6602e-01,  9.0413e-01,  1.4115e+00,  1.6582e+00,  1.8032e+00,\n",
      "          1.9766e+00,  5.5776e-01,  2.9160e+00,  1.2454e+00,  1.4701e-02],\n",
      "        [ 9.5889e-01,  3.4822e+00,  1.1964e+00,  9.8591e-01,  2.9883e+00,\n",
      "          1.5478e+00,  9.5809e-01,  2.2612e+00,  2.2052e+00,  2.1110e+00,\n",
      "          1.0211e+00, -4.9400e-01,  2.6154e+00,  1.7449e+00,  1.2273e-01,\n",
      "          3.1113e-01,  5.8027e-01,  1.1837e+00,  2.3249e+00,  2.3217e+00,\n",
      "          2.0922e+00,  7.9729e-01,  2.8894e+00,  1.8558e+00, -1.7915e-02],\n",
      "        [ 1.3259e+00,  3.0498e+00,  1.4667e+00,  1.1342e+00,  3.4605e+00,\n",
      "          1.8028e+00,  2.0074e+00,  2.8917e+00,  2.1129e+00,  1.9411e+00,\n",
      "          1.0197e+00, -1.1762e+00,  2.9185e+00,  1.7926e+00,  2.4569e-01,\n",
      "          3.9129e-01,  8.3668e-01,  9.3326e-01,  1.6704e+00,  1.7996e+00,\n",
      "          2.3371e+00,  8.6402e-01,  2.9976e+00,  1.4860e+00,  8.4811e-02],\n",
      "        [ 1.2366e+00,  2.8138e+00,  1.5206e+00,  8.0115e-01,  2.6399e+00,\n",
      "          2.0128e+00,  1.4723e+00,  2.8569e+00,  2.7116e+00,  1.8108e+00,\n",
      "          1.2782e+00, -1.0195e+00,  2.3833e+00,  1.6010e+00,  3.7449e-01,\n",
      "          4.5534e-01,  8.4327e-01,  1.1002e+00,  1.8099e+00,  1.7701e+00,\n",
      "          2.8505e+00,  9.4318e-01,  2.9494e+00,  1.9104e+00,  1.6999e-01],\n",
      "        [ 1.2538e+00,  3.0971e+00,  1.3343e+00,  1.2200e+00,  2.2429e+00,\n",
      "          1.6440e+00,  1.2161e+00,  2.5546e+00,  1.9710e+00,  2.5115e+00,\n",
      "          1.1558e+00, -5.7233e-01,  2.5706e+00,  1.5284e+00,  1.0493e-01,\n",
      "          1.2287e-01,  1.0832e+00,  1.3854e+00,  1.3912e+00,  1.8853e+00,\n",
      "          2.7997e+00,  9.2446e-01,  2.9825e+00,  1.5461e+00, -6.3389e-02],\n",
      "        [ 1.4086e+00,  3.1178e+00,  1.3195e+00,  7.1995e-01,  2.7601e+00,\n",
      "          2.4807e+00,  6.2433e-01,  2.5414e+00,  2.6087e+00,  1.7639e+00,\n",
      "          1.0757e+00, -5.2571e-01,  2.6283e+00,  1.4437e+00,  7.9383e-02,\n",
      "          2.1213e-01,  1.4344e+00,  6.8720e-01,  1.5307e+00,  1.8443e+00,\n",
      "          2.4047e+00,  8.2733e-01,  2.8776e+00,  1.2427e+00,  2.7106e-01],\n",
      "        [ 6.6120e-01,  2.8268e+00,  1.8641e+00,  1.2542e+00,  3.2515e+00,\n",
      "          1.8983e+00,  1.3993e+00,  2.4116e+00,  1.9135e+00,  1.8894e+00,\n",
      "          1.0560e+00, -8.7686e-01,  2.5003e+00,  1.9701e+00,  3.0594e-01,\n",
      "          5.5060e-01,  4.4929e-01,  1.3384e+00,  1.6428e+00,  1.9485e+00,\n",
      "          2.4856e+00,  7.8147e-01,  2.7899e+00,  1.8813e+00,  2.5219e-01],\n",
      "        [ 9.8855e-01,  3.4701e+00,  1.5249e+00,  1.2296e+00,  2.9436e+00,\n",
      "          2.3752e+00,  1.3664e+00,  2.6265e+00,  2.1939e+00,  2.1924e+00,\n",
      "          8.8736e-01, -6.5503e-01,  2.3746e+00,  2.0188e+00,  9.3733e-01,\n",
      "          2.8907e-01,  1.0050e+00,  1.5042e+00,  1.5190e+00,  2.1823e+00,\n",
      "          2.3442e+00,  1.2635e+00,  3.1788e+00,  1.8523e+00,  4.2905e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.5271, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.6257,  2.5201,  2.1585,  1.2277,  2.2143,  1.8155,  2.5528,  3.0629,\n",
      "          1.6295,  3.1345,  0.8429, -1.8356,  2.8868,  1.2967,  0.4583,  0.8523,\n",
      "          1.2063,  1.3510,  0.5431,  1.7164,  2.4150,  0.9450,  2.9606,  2.1961,\n",
      "          0.3867],\n",
      "        [ 0.6153,  2.6226,  2.7441,  0.8587,  2.5553,  2.3128,  1.6830,  2.8768,\n",
      "          1.3191,  2.4797,  0.9179, -1.3306,  2.4083,  1.8368,  0.5516,  0.8378,\n",
      "          1.2787,  1.1381,  1.1209,  1.2604,  2.1152,  0.6038,  2.9419,  1.3064,\n",
      "          0.1217],\n",
      "        [ 0.4287,  2.8626,  2.6578,  1.3547,  2.6199,  1.5199,  2.0258,  3.2822,\n",
      "          1.5228,  2.6350,  0.8504, -1.5821,  2.9469,  1.9050,  0.1796,  0.4759,\n",
      "          1.6416,  0.9331,  1.8087,  0.9399,  2.1096,  0.1938,  2.7381,  1.1668,\n",
      "          0.0175],\n",
      "        [ 1.3219,  3.0646,  2.8013,  0.3593,  1.8686,  1.9716,  1.9914,  2.6637,\n",
      "          1.0096,  2.4421,  1.1291, -1.7120,  2.7872,  1.8009,  0.4111,  0.3307,\n",
      "          2.1678,  1.0778,  0.5519,  0.3733,  2.1405,  0.8794,  2.8939,  1.1994,\n",
      "          0.0539],\n",
      "        [ 1.2434,  2.3871,  2.6036,  1.0297,  2.5474,  1.9613,  2.1764,  2.9799,\n",
      "          1.2459,  2.7822,  1.3026, -1.4029,  2.3483,  1.6648,  0.1434,  0.5027,\n",
      "          1.4835,  1.1218,  0.9530,  1.1408,  2.2168,  0.8044,  2.4893,  1.4429,\n",
      "         -0.1260],\n",
      "        [ 0.7298,  2.0892,  2.6219,  1.0454,  2.1955,  1.7835,  1.7025,  2.6193,\n",
      "          1.3092,  2.4940,  1.1931, -1.4819,  2.3229,  1.9197,  0.1714,  0.7377,\n",
      "          1.7200,  0.9427,  1.0647,  0.6057,  2.3791,  0.8379,  2.8564,  1.1188,\n",
      "          0.1728],\n",
      "        [ 0.9569,  2.0420,  2.4589,  0.9430,  2.5829,  2.0574,  2.7974,  2.4421,\n",
      "          1.1205,  2.5159,  0.8334, -1.4997,  2.9208,  1.4536,  0.1166,  0.8261,\n",
      "          1.1244,  1.3249,  0.4691,  0.6369,  2.3036,  0.8936,  2.4621,  1.2305,\n",
      "          0.4304],\n",
      "        [ 0.8627,  2.5848,  2.8183,  1.0306,  2.4903,  1.7741,  1.9192,  3.2363,\n",
      "          1.4493,  3.0601,  1.0271, -1.7551,  2.7303,  1.4443,  0.3656,  0.6602,\n",
      "          1.0783,  1.5006,  1.0033,  1.1549,  2.2444,  0.8098,  3.1580,  1.1206,\n",
      "          0.3033],\n",
      "        [ 0.9742,  2.5815,  2.5652,  1.1753,  3.1798,  1.4121,  2.2295,  2.9215,\n",
      "          1.2355,  2.8061,  0.6655, -1.5322,  2.4754,  1.9056,  0.8326,  0.0768,\n",
      "          1.5048,  1.0893,  0.9927,  1.0803,  2.3241,  0.9236,  3.0293,  1.5503,\n",
      "          0.0602],\n",
      "        [ 0.7334,  2.9217,  1.8607,  0.5924,  2.3668,  1.9903,  2.5465,  2.6165,\n",
      "          1.1510,  3.1385,  0.8341, -1.1756,  2.8324,  1.7060,  0.6258,  0.6329,\n",
      "          1.8189,  1.2248,  0.4446,  0.9822,  2.1943,  0.8757,  2.7691,  1.6640,\n",
      "          0.4310],\n",
      "        [ 0.9731,  2.4122,  2.5760,  0.9691,  2.0124,  1.8221,  1.4598,  2.7450,\n",
      "          1.7014,  2.6361,  1.0597, -1.1864,  2.5704,  1.8335,  0.7130,  0.5568,\n",
      "          1.1820,  0.8234,  1.1756,  0.7271,  2.2620,  0.2436,  2.6816,  1.3261,\n",
      "          0.3937],\n",
      "        [ 0.7918,  2.8609,  2.1845,  1.0357,  2.4987,  2.1382,  2.2756,  2.9421,\n",
      "          1.8137,  3.0066,  0.9438, -1.6675,  2.4340,  1.3039,  0.8904,  0.3067,\n",
      "          1.0073,  1.2633,  0.5691,  1.4829,  2.5786,  0.6943,  3.2765,  1.8097,\n",
      "          0.1323],\n",
      "        [ 1.1398,  2.7911,  2.5158,  0.5390,  2.3017,  1.8398,  2.7467,  2.4885,\n",
      "          1.2540,  2.7195,  0.8919, -1.6359,  2.5893,  1.4432,  0.4658,  0.4642,\n",
      "          1.8704,  1.1481,  0.1990,  1.4528,  2.6280,  0.8274,  2.8876,  1.2943,\n",
      "          0.2949],\n",
      "        [ 0.7539,  2.5594,  2.5146,  0.6245,  2.8116,  2.0203,  1.9131,  2.9876,\n",
      "          1.7364,  2.3911,  0.9972, -1.7200,  2.6976,  1.6448,  0.0677,  0.6148,\n",
      "          1.6523,  1.0511,  1.2541,  0.8613,  2.3459,  0.5484,  2.8557,  1.1683,\n",
      "         -0.1456],\n",
      "        [ 0.9122,  2.9845,  2.4344,  1.1107,  2.9617,  1.8351,  2.5666,  2.6347,\n",
      "          1.5286,  2.9040,  0.4638, -1.6992,  3.1520,  1.8130, -0.2691,  0.6773,\n",
      "          1.1008,  0.8787,  0.5917,  1.4054,  2.2342,  0.8177,  3.1879,  1.6682,\n",
      "          0.3349],\n",
      "        [ 0.7125,  2.7334,  1.8736,  1.0834,  2.5556,  1.6271,  2.3826,  2.5584,\n",
      "          1.2859,  2.7912,  0.7623, -1.3904,  2.9477,  1.4300,  0.2835,  0.9281,\n",
      "          1.5077,  1.1838,  0.5762,  1.6393,  2.0150,  0.7890,  2.4760,  1.6534,\n",
      "          0.3515],\n",
      "        [ 0.8133,  2.4567,  2.0502,  1.1396,  2.2659,  1.6268,  2.2053,  2.8504,\n",
      "          1.2264,  2.7006,  1.4305, -1.2338,  2.6569,  1.6562,  0.2532,  0.6486,\n",
      "          1.8510,  1.3906,  0.9336,  1.1271,  1.9755,  0.3284,  2.4524,  1.6170,\n",
      "         -0.2756],\n",
      "        [ 1.0067,  2.5709,  2.3004,  0.8777,  2.9995,  1.3788,  1.8832,  2.8818,\n",
      "          1.3919,  2.7018,  1.4789, -1.9392,  2.9887,  1.7095,  0.0593,  0.4219,\n",
      "          1.0410,  0.6689,  1.1236,  0.6952,  1.9283,  0.5991,  2.9374,  1.2643,\n",
      "         -0.3161],\n",
      "        [ 0.7845,  2.2506,  2.5539,  0.9263,  2.2538,  1.4508,  1.9801,  2.9291,\n",
      "          1.3318,  2.8441,  1.1265, -1.6118,  2.9383,  1.3278,  0.0215,  0.5278,\n",
      "          1.3165,  1.4514,  0.7066,  0.9178,  1.9526,  0.7100,  2.7916,  1.2107,\n",
      "          0.2983],\n",
      "        [ 0.7098,  2.9408,  2.5015,  0.9915,  3.0265,  1.7238,  2.3293,  3.0848,\n",
      "          1.2692,  2.4714,  0.8030, -1.8949,  2.9200,  1.6397,  0.9245,  0.2774,\n",
      "          1.1013,  0.9515,  1.0101,  1.3039,  2.2913,  1.2908,  3.1137,  1.4741,\n",
      "          0.0502],\n",
      "        [ 1.0664,  2.6694,  1.9231,  0.6336,  2.4542,  2.1826,  2.6748,  3.1678,\n",
      "          1.1438,  3.3243,  0.8414, -1.3101,  2.4838,  1.4980,  0.2639,  1.1500,\n",
      "          1.6292,  1.0754,  0.4725,  1.3032,  1.8050,  0.8197,  2.4165,  1.8059,\n",
      "          0.1957],\n",
      "        [ 1.0038,  2.5952,  2.2731,  0.9010,  2.1149,  1.7445,  2.3258,  2.5718,\n",
      "          1.4745,  2.8250,  1.2048, -1.6196,  2.6243,  1.3229,  0.4853,  0.7564,\n",
      "          1.5047,  1.4241,  0.6683,  1.0848,  2.3653,  0.4958,  2.9515,  1.6785,\n",
      "          0.0651],\n",
      "        [ 1.0985,  2.6515,  2.1978,  1.0521,  2.2945,  1.6382,  2.4801,  2.8419,\n",
      "          1.7260,  3.4918,  1.5223, -0.8877,  2.3010,  1.3214,  0.6296,  0.6416,\n",
      "          1.2442,  1.3934,  0.8798,  1.4452,  2.2428,  0.7388,  2.9573,  1.9233,\n",
      "         -0.0153],\n",
      "        [ 0.7868,  2.9617,  2.4628,  0.9890,  2.5753,  1.7733,  2.5189,  2.6936,\n",
      "          1.3046,  2.6731,  1.0506, -1.5465,  2.5647,  1.4807,  0.9270,  0.6793,\n",
      "          1.2318,  1.4569,  1.0883,  1.1514,  2.3599,  0.7489,  2.9456,  1.5893,\n",
      "          0.4883],\n",
      "        [ 0.9413,  2.8957,  2.0119,  1.1501,  2.4282,  1.9071,  2.2438,  3.2534,\n",
      "          1.4516,  2.7928,  1.1811, -1.3210,  2.6538,  1.4006,  0.6616,  0.7994,\n",
      "          0.5223,  0.7864,  0.5587,  0.8754,  2.0697,  1.0139,  3.0321,  1.8479,\n",
      "          0.5849],\n",
      "        [ 0.9280,  3.0869,  2.2106,  0.9300,  2.7208,  1.6253,  2.4204,  2.9652,\n",
      "          1.2987,  2.8988,  1.0805, -1.6055,  2.9898,  1.4979,  0.3225,  0.7202,\n",
      "          1.4416,  1.2869,  0.6876,  0.8789,  2.2381,  0.9821,  3.3054,  1.4686,\n",
      "          0.3442],\n",
      "        [ 0.6210,  2.7460,  2.4027,  1.5315,  3.1571,  1.7701,  2.6816,  3.1639,\n",
      "          1.8213,  2.7810,  1.3609, -1.6195,  2.9745,  1.1809,  0.5343,  0.9199,\n",
      "          0.8852,  0.6821,  1.1694,  1.4555,  2.0578,  0.9657,  2.9167,  2.1238,\n",
      "         -0.1996],\n",
      "        [ 0.7670,  3.0100,  2.1793,  0.9526,  2.7788,  2.0222,  2.3467,  2.6920,\n",
      "          1.2011,  2.0752,  0.6231, -1.5051,  2.6577,  1.7712,  0.2396,  0.8624,\n",
      "          1.7092,  0.8646,  0.8657,  1.0544,  2.1147,  0.3972,  2.7041,  1.2044,\n",
      "          0.5153],\n",
      "        [ 0.7015,  2.7212,  2.5740,  0.9545,  3.3385,  1.7059,  2.3006,  2.8490,\n",
      "          1.5412,  2.5478,  0.9271, -1.8800,  2.5910,  1.6005,  0.4658,  0.6774,\n",
      "          1.1384,  0.9882,  1.9236,  0.9289,  2.1412,  0.7110,  2.6845,  1.4474,\n",
      "          0.3062],\n",
      "        [ 0.8831,  2.2607,  2.2753,  1.0171,  2.2415,  2.2070,  1.8099,  2.6371,\n",
      "          1.5594,  3.2758,  0.7178, -1.3820,  2.6112,  1.4536,  0.3485,  0.9624,\n",
      "          1.1091,  1.2108,  0.8540,  1.4177,  2.0169,  0.6833,  2.8749,  1.4966,\n",
      "          0.3436],\n",
      "        [ 0.7896,  2.4614,  2.3204,  0.9148,  2.4529,  1.9338,  2.1819,  3.2127,\n",
      "          1.2272,  2.4564,  1.2213, -1.5949,  2.4156,  1.5740,  0.3416,  0.7912,\n",
      "          1.3613,  0.9391,  0.8256,  1.2083,  1.9252,  0.5022,  3.0920,  1.7948,\n",
      "         -0.1953],\n",
      "        [ 1.0776,  2.7291,  2.7138,  0.5792,  2.0576,  1.7506,  1.8920,  2.4418,\n",
      "          1.4170,  2.8819,  0.9995, -1.7236,  2.6344,  1.5728,  0.7496,  0.5961,\n",
      "          1.4926,  1.4673,  0.8354,  1.0030,  2.0576,  0.6872,  3.0508,  0.9833,\n",
      "          0.1156]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.7131, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.6228,  2.0681,  2.8987,  0.8186,  2.2576,  1.6750,  2.4353,  3.3267,\n",
      "          0.9177,  2.9666,  1.0483, -2.2332,  2.6417,  1.4358,  1.2662,  1.1188,\n",
      "          1.5689,  1.3639,  0.8963,  0.4186,  1.5238,  0.6415,  2.4454,  1.4257,\n",
      "          0.5688],\n",
      "        [ 0.9250,  1.9766,  3.0641,  0.6286,  2.0099,  1.9298,  2.8782,  3.4298,\n",
      "          1.0278,  3.0373,  1.4022, -1.9770,  2.4849,  1.0301,  1.1440,  0.9283,\n",
      "          1.9182,  1.7220,  0.5332,  0.5798,  1.7648,  0.4699,  2.5187,  1.9190,\n",
      "         -0.0401],\n",
      "        [ 0.9047,  2.1626,  2.6498,  0.9121,  1.9643,  1.7288,  2.7568,  3.3719,\n",
      "          1.5635,  3.2703,  0.9803, -1.9632,  2.8548,  1.6264,  1.1864,  1.0476,\n",
      "          1.9973,  1.5840,  0.5192,  0.8559,  1.7463,  0.4005,  2.5090,  2.2123,\n",
      "          0.5468],\n",
      "        [ 0.4223,  2.3683,  3.4378,  1.1090,  2.8169,  1.8775,  3.2172,  3.5639,\n",
      "          0.6228,  3.1095,  1.0398, -2.5578,  2.9954,  1.0664,  0.5673,  1.1954,\n",
      "          1.8127,  1.6359,  0.4935,  0.6401,  1.2539,  0.5898,  2.4981,  2.0403,\n",
      "          0.4923],\n",
      "        [ 0.7042,  2.1929,  2.9648,  1.1460,  2.4132,  1.6708,  3.6569,  3.0850,\n",
      "          1.1135,  3.1581,  0.9369, -2.0555,  2.8558,  0.9781,  0.7368,  1.3230,\n",
      "          1.7001,  1.8220, -0.1117,  0.4094,  2.0840,  0.7710,  2.3020,  1.9567,\n",
      "          0.2865],\n",
      "        [ 0.5230,  2.7101,  3.4295,  1.0387,  1.8202,  1.4230,  3.0142,  3.2322,\n",
      "          1.5086,  2.9012,  1.1665, -2.0808,  2.9098,  1.3167,  1.2497,  1.1200,\n",
      "          1.5153,  1.1889,  0.4960,  0.6688,  1.2333,  0.3982,  2.8574,  2.2030,\n",
      "          0.5557],\n",
      "        [ 0.7361,  1.6562,  2.8522,  0.7146,  2.0729,  1.5149,  2.4606,  2.5592,\n",
      "          0.9178,  2.7937,  0.9464, -1.9834,  2.6585,  0.9507,  1.0680,  1.2738,\n",
      "          2.0435,  1.7913,  0.2651,  0.4434,  1.2893,  0.4580,  2.7744,  1.8241,\n",
      "          0.0195],\n",
      "        [ 0.4550,  2.3173,  3.3267,  0.5456,  2.1746,  1.3661,  2.8278,  2.8729,\n",
      "          0.9958,  2.7548,  1.5124, -1.6451,  2.7645,  1.1117,  0.6474,  1.1056,\n",
      "          1.8634,  1.4439,  0.3376,  0.4844,  1.6652,  0.7199,  2.5113,  1.5026,\n",
      "          0.1212],\n",
      "        [ 0.7581,  2.0351,  3.0096,  1.0054,  1.8519,  2.1643,  2.7553,  3.0366,\n",
      "          1.3498,  3.1709,  1.3331, -1.9609,  2.6170,  1.1111,  1.1746,  1.4112,\n",
      "          1.7501,  1.4448,  0.1835,  0.4013,  1.5333,  0.6068,  2.5198,  1.3998,\n",
      "          0.4371],\n",
      "        [ 0.6697,  1.7246,  2.8401,  0.9212,  2.2799,  1.6748,  2.9168,  2.9854,\n",
      "          1.4080,  3.0602,  1.2852, -2.2917,  2.8725,  1.5247,  0.6747,  1.0144,\n",
      "          2.3839,  1.6257,  0.9513,  0.1296,  1.8175,  0.9061,  2.5206,  1.3798,\n",
      "         -0.2246],\n",
      "        [ 0.5333,  2.6727,  2.8828,  0.7333,  2.8326,  2.0446,  3.3690,  3.4079,\n",
      "          0.8952,  2.8232,  0.9545, -2.5444,  2.6900,  1.2494,  0.9518,  1.0686,\n",
      "          1.9269,  1.6937,  0.6061,  0.8168,  1.9470,  0.6886,  2.6490,  1.4075,\n",
      "          0.4155],\n",
      "        [ 0.8031,  2.2244,  3.1279,  0.9487,  2.0350,  2.0105,  2.9737,  3.0948,\n",
      "          1.0636,  3.1317,  1.1182, -2.3837,  2.9679,  1.1434,  0.8447,  1.6718,\n",
      "          1.9009,  1.9040,  0.2952,  0.7882,  1.2481,  0.7442,  2.9209,  1.6140,\n",
      "          0.5841],\n",
      "        [ 0.8703,  2.0073,  3.2117,  0.6435,  1.7522,  1.6593,  2.3004,  3.1928,\n",
      "          1.2277,  2.8714,  1.1320, -2.1152,  2.5927,  1.4057,  0.7492,  1.0095,\n",
      "          2.2015,  1.4301,  0.6726,  0.8093,  1.4043,  0.5550,  2.8544,  1.3908,\n",
      "          0.4016],\n",
      "        [ 0.8858,  2.6960,  2.8412,  0.4029,  2.0151,  2.0581,  2.6282,  3.0583,\n",
      "          0.6475,  3.3222,  1.6281, -2.0301,  2.3400,  1.4477,  1.0926,  1.0613,\n",
      "          2.3109,  1.4355,  0.0990,  0.4195,  1.7873,  0.4667,  2.9512,  1.6537,\n",
      "          0.0622],\n",
      "        [ 0.5500,  2.2400,  2.6650,  0.7212,  2.1284,  1.8220,  2.4950,  3.2602,\n",
      "          0.7541,  3.1308,  1.2212, -2.3490,  2.6444,  1.3057,  1.3073,  1.0149,\n",
      "          1.8288,  0.9716,  0.3150,  0.3716,  2.0067,  0.7697,  3.1281,  1.5076,\n",
      "          0.1265],\n",
      "        [ 0.6619,  1.8366,  2.7710,  0.8719,  2.0335,  1.4750,  2.9386,  3.0134,\n",
      "          1.1392,  2.8871,  1.5072, -2.1992,  2.5712,  1.1817,  1.1649,  0.8695,\n",
      "          2.0219,  1.3882,  0.1912,  0.4270,  1.6412,  0.8997,  2.7746,  1.4070,\n",
      "          0.3886],\n",
      "        [ 0.7681,  2.0603,  2.8420,  0.7482,  2.2568,  1.9285,  2.8717,  3.1766,\n",
      "          0.8742,  2.5071,  1.1746, -2.0833,  2.8817,  1.3439,  0.7562,  1.0746,\n",
      "          1.9188,  1.5359,  0.4387,  0.4532,  1.5195,  0.6437,  2.9410,  1.7176,\n",
      "          0.6603],\n",
      "        [ 1.0022,  1.9285,  3.1555,  0.9142,  2.0805,  1.3634,  2.7173,  2.7451,\n",
      "          1.1992,  2.7743,  0.5704, -1.6833,  2.8189,  1.1574,  0.6996,  1.0025,\n",
      "          1.9063,  1.6955,  0.2018,  0.7522,  1.3226,  0.5229,  2.5604,  1.7679,\n",
      "          0.6475],\n",
      "        [ 0.6445,  2.1201,  2.8889,  1.0933,  2.0995,  2.0525,  2.9919,  3.0763,\n",
      "          1.3111,  2.7900,  1.2450, -1.7287,  2.2657,  1.3282,  1.0644,  1.4917,\n",
      "          1.1450,  1.0824,  0.0211,  0.7390,  1.6153,  1.0194,  3.1109,  2.4056,\n",
      "          0.4156],\n",
      "        [ 0.6826,  2.3336,  3.2450,  0.5952,  2.0113,  2.0025,  2.3856,  3.3359,\n",
      "          1.0873,  3.2578,  1.1535, -1.6061,  2.6884,  1.1298,  0.3934,  1.0467,\n",
      "          1.6784,  1.2787,  0.3500,  0.5403,  1.3536,  0.7711,  2.7364,  1.6999,\n",
      "          0.3265],\n",
      "        [ 0.7792,  1.8471,  2.7595,  0.8435,  2.6657,  1.9676,  2.7807,  3.1513,\n",
      "          1.2954,  3.1245,  1.0726, -1.7010,  2.8746,  1.4218,  0.7423,  1.2547,\n",
      "          1.3113,  1.1814,  0.3908,  0.8406,  1.6709,  0.9781,  2.6686,  1.8479,\n",
      "          0.3256],\n",
      "        [ 0.1655,  2.2819,  2.8034,  0.9443,  2.6616,  1.8142,  3.3174,  3.1673,\n",
      "          1.2599,  3.1046,  1.2459, -2.2246,  2.8973,  1.1330,  1.1627,  1.3888,\n",
      "          1.7594,  1.3917,  0.1965,  0.7447,  1.8528,  0.8272,  3.0761,  2.0426,\n",
      "          0.4940],\n",
      "        [ 0.7512,  2.6155,  2.8944,  1.0409,  1.7748,  1.9063,  2.9139,  3.5359,\n",
      "          1.1111,  3.1218,  0.7536, -2.0828,  2.1792,  0.9540,  1.3522,  0.8288,\n",
      "          1.8289,  1.1958,  0.5122,  0.3635,  1.6983,  0.7404,  2.7372,  1.5397,\n",
      "          0.3467],\n",
      "        [ 0.6303,  1.9578,  3.1501,  0.9162,  1.7832,  2.2617,  2.6267,  3.0754,\n",
      "          0.7774,  3.4467,  1.0053, -2.0169,  2.4171,  1.0272,  0.9957,  1.2497,\n",
      "          1.7191,  1.4328,  0.6919,  0.7007,  1.1584,  0.8000,  2.6238,  1.5921,\n",
      "          0.4159],\n",
      "        [ 0.3760,  2.3276,  2.8902,  0.7066,  2.6722,  1.9700,  2.9066,  2.7887,\n",
      "          0.9647,  3.2098,  0.7662, -2.4672,  2.8384,  1.9149,  0.7133,  0.9712,\n",
      "          1.5698,  1.0995,  0.6757,  0.3212,  1.9397,  1.0681,  2.8038,  1.5530,\n",
      "          0.1801],\n",
      "        [ 0.7626,  2.0178,  2.9479,  1.1644,  1.9760,  1.6844,  2.6157,  2.9357,\n",
      "          1.4000,  3.5634,  1.1215, -2.0779,  2.6920,  1.5135,  0.9801,  0.7255,\n",
      "          2.0867,  1.0332,  0.1497,  0.2692,  1.6219,  0.3556,  2.9902,  1.5241,\n",
      "          0.5742],\n",
      "        [ 0.8750,  2.6513,  2.9409,  0.4230,  2.0073,  2.2757,  2.9783,  3.2292,\n",
      "          1.0286,  2.7158,  1.0063, -2.2085,  2.7674,  1.1683,  1.6578,  1.2963,\n",
      "          1.9595,  1.2341,  0.4180,  0.1785,  1.7379,  0.7746,  2.7820,  1.6263,\n",
      "          0.7926],\n",
      "        [ 0.7029,  2.1735,  2.6318,  0.9659,  2.9363,  1.9854,  3.1010,  3.2983,\n",
      "          1.2654,  2.9862,  1.4635, -1.9711,  2.8733,  1.4131,  0.7828,  1.4244,\n",
      "          1.7511,  1.3341,  0.0154,  0.8333,  1.6687,  0.8030,  2.3637,  1.4965,\n",
      "          0.0084],\n",
      "        [ 0.6421,  1.8680,  3.2554,  0.7187,  2.4729,  1.6794,  2.9563,  2.8924,\n",
      "          1.0943,  3.3088,  1.1190, -2.0318,  2.6779,  1.1150,  1.2696,  1.0678,\n",
      "          1.7371,  1.6186, -0.3043,  0.6615,  1.3856,  0.8511,  2.9820,  1.8224,\n",
      "          0.3665],\n",
      "        [ 0.7093,  2.2691,  2.9450,  0.6084,  2.0239,  2.0954,  2.8827,  3.3535,\n",
      "          1.0795,  2.9623,  1.1933, -2.5478,  2.6938,  1.0942,  1.2164,  1.2623,\n",
      "          2.0962,  1.6672,  0.4417,  0.4618,  1.3921,  0.6162,  2.7365,  1.5060,\n",
      "          0.2475],\n",
      "        [ 0.8070,  2.6377,  3.1513,  0.2413,  1.9164,  2.1851,  2.7462,  2.9052,\n",
      "          0.4166,  2.9499,  1.1961, -2.1690,  2.5135,  1.2037,  1.0250,  1.2756,\n",
      "          2.1750,  1.1622,  0.3993,  0.2599,  1.5470,  0.6043,  2.4275,  0.9222,\n",
      "          0.4587],\n",
      "        [ 0.7909,  2.0197,  3.3869,  0.7375,  2.0200,  1.6501,  3.0395,  2.9699,\n",
      "          1.2463,  2.9246,  1.3410, -2.1941,  2.8132,  1.5154,  1.0986,  0.9466,\n",
      "          1.7097,  1.3624,  0.7473,  0.3543,  1.3214,  0.5683,  2.9769,  1.4479,\n",
      "          0.4575]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(4.0322, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.9015,  1.8506,  3.8614,  0.3845,  1.7782,  1.9101,  2.9064,  2.6500,\n",
      "          0.7685,  1.9486,  0.9836, -2.4499,  2.6371,  1.3217,  1.0569,  1.5621,\n",
      "          2.1600,  1.5989,  0.8317,  0.6231,  1.0097,  0.9204,  1.7134,  1.5866,\n",
      "          0.7940],\n",
      "        [ 1.0171,  1.5176,  3.5896,  0.4124,  1.7905,  1.6830,  3.1978,  2.8336,\n",
      "          0.7283,  2.0691,  1.2339, -1.9345,  2.6096,  0.8981,  1.2220,  1.5792,\n",
      "          2.0300,  1.7314,  0.7441,  0.9062,  1.2779,  1.1213,  1.7969,  1.7386,\n",
      "          0.4460],\n",
      "        [ 0.9438,  1.3111,  3.2685,  0.6415,  1.4879,  1.8352,  2.9434,  2.8658,\n",
      "          1.1516,  2.5681,  1.1227, -1.8816,  2.4321,  1.0182,  1.0421,  1.8717,\n",
      "          2.1033,  1.8111,  0.0946,  0.2586,  0.9334,  0.8863,  2.8494,  2.3022,\n",
      "          0.5590],\n",
      "        [ 1.0353,  0.8656,  3.3958,  0.6818,  1.3932,  1.7241,  3.2067,  2.3313,\n",
      "          1.2426,  2.4882,  1.2820, -2.4663,  2.5570,  0.6556,  1.3490,  1.4798,\n",
      "          1.6921,  2.0879, -0.1087,  0.6192,  1.2176,  0.9514,  2.4385,  1.6913,\n",
      "          0.7691],\n",
      "        [ 0.8901,  1.2681,  3.1914,  0.5531,  2.2365,  1.7688,  2.8592,  2.9890,\n",
      "          0.6757,  1.6551,  0.8349, -2.2800,  2.7072,  1.2177,  0.9110,  1.7510,\n",
      "          2.0361,  1.7905,  0.3525,  0.4500,  1.3496,  1.2539,  1.7424,  1.5653,\n",
      "          1.0197],\n",
      "        [ 0.9683,  1.7916,  3.6326,  0.5169,  1.5316,  2.2953,  2.9736,  2.7061,\n",
      "          0.7629,  2.1027,  0.8581, -2.0759,  2.3689,  0.8051,  0.9922,  2.1559,\n",
      "          1.6910,  1.1933,  0.8021,  0.6501,  1.0265,  1.0080,  1.8888,  1.6940,\n",
      "          0.8669],\n",
      "        [ 1.1033,  1.6753,  3.8006,  0.6211,  1.6157,  1.9975,  2.7627,  2.8711,\n",
      "          1.0026,  2.6150,  1.2521, -1.6990,  2.2221,  1.4340,  1.0827,  1.7227,\n",
      "          2.1501,  1.4719,  0.1941,  0.5731,  0.9235,  0.9773,  2.0403,  2.0396,\n",
      "          0.7252],\n",
      "        [ 0.5903,  1.8109,  3.6642,  0.8392,  1.7558,  1.9191,  2.8621,  2.3130,\n",
      "          0.9014,  2.6793,  0.8967, -2.1716,  3.1453,  1.2237,  1.1457,  1.6915,\n",
      "          1.9657,  1.8705,  0.3768,  1.0416,  0.8185,  0.8478,  1.6927,  1.7941,\n",
      "          0.6455],\n",
      "        [ 0.6592,  1.2704,  3.4323,  0.9215,  2.1998,  1.4291,  3.1640,  2.5345,\n",
      "          0.7907,  2.1359,  0.8012, -2.1590,  2.6194,  1.1444,  1.1806,  1.9814,\n",
      "          1.7290,  1.8164,  0.2897,  0.6922,  1.1251,  1.1075,  2.3242,  2.0190,\n",
      "          0.7997],\n",
      "        [ 1.1849,  1.8169,  3.7318,  0.3717,  1.5354,  1.9480,  2.9834,  2.7708,\n",
      "          0.9927,  2.5366,  1.2680, -2.3486,  2.2553,  0.5420,  1.4169,  2.1092,\n",
      "          2.0893,  2.4630,  0.1121,  1.2292,  1.3822,  0.8210,  2.2250,  2.5938,\n",
      "          0.4103],\n",
      "        [ 0.9983,  1.0920,  3.7982,  0.7033,  1.3225,  1.5064,  2.4863,  2.8014,\n",
      "          0.7084,  2.6738,  1.2376, -2.5991,  2.8106,  0.9229,  1.5354,  1.1278,\n",
      "          1.9866,  1.9606,  0.1325,  0.2403,  1.2965,  1.2678,  2.2166,  1.7095,\n",
      "          0.1255],\n",
      "        [ 1.0828,  1.2137,  3.6524,  0.0765,  1.2918,  1.9340,  2.8294,  2.7829,\n",
      "          0.6809,  1.8058,  1.1834, -2.1741,  2.7290,  0.8639,  0.8310,  1.2496,\n",
      "          2.0615,  1.6401,  0.0531,  0.3196,  1.4936,  1.2667,  2.1500,  1.7492,\n",
      "          0.8554],\n",
      "        [ 0.8231,  1.6475,  3.4090,  0.4697,  2.2659,  1.2093,  2.8730,  2.7743,\n",
      "          1.0809,  2.0532,  1.0032, -2.3370,  2.8575,  1.3837,  1.2835,  1.4145,\n",
      "          2.1115,  1.7468,  0.5608,  0.2908,  1.1957,  1.0422,  1.9632,  1.6910,\n",
      "          0.1670],\n",
      "        [ 0.8976,  1.9047,  3.5518,  1.0425,  1.5335,  2.1681,  3.1167,  3.0768,\n",
      "          0.8708,  2.6307,  1.0135, -2.0301,  2.2457,  0.9797,  1.2498,  1.8357,\n",
      "          2.1038,  1.6650,  0.0095,  0.8717,  1.2915,  0.8309,  2.1087,  2.3575,\n",
      "          0.4579]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch:1, Average Training Loss=3.6851858139038085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 1/4 [01:30<04:30, 90.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Average Validation Accuracy=0.06451612903225806\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.3228, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.4622,  0.6526,  3.7338,  0.4609,  0.7708,  1.0031,  2.7231,  2.2165,\n",
      "          0.1917,  1.0277,  1.4663, -1.6596,  2.2434,  1.1784,  1.7633,  2.4215,\n",
      "          2.9184,  2.8001,  0.5235,  1.0440,  0.9536,  1.2370,  1.1063,  1.6289,\n",
      "          1.0880],\n",
      "        [ 1.1168,  0.4575,  3.3379,  0.6884,  1.3221,  1.6813,  1.8410,  2.3661,\n",
      "          0.7386,  1.4228,  1.2347, -1.6739,  2.6804,  1.7337,  1.3859,  2.5826,\n",
      "          2.4778,  2.0398,  0.8556,  0.4033,  1.5717,  1.1913,  1.5061,  1.5513,\n",
      "          1.5737],\n",
      "        [ 0.8174,  0.9408,  3.4063,  0.2035,  1.3586,  2.0401,  2.8410,  1.8962,\n",
      "          0.6569,  1.1948,  0.9967, -2.3780,  2.5792,  1.1411,  1.7975,  2.7512,\n",
      "          1.7779,  2.3475,  0.6504,  0.7877,  0.8750,  1.1556,  1.3970,  1.8844,\n",
      "          1.3274],\n",
      "        [ 1.2611,  0.2158,  3.5033,  0.4387,  0.6141,  1.4328,  2.2780,  2.5702,\n",
      "          0.6332,  1.7626,  1.5586, -1.5137,  2.2787,  0.9886,  2.1436,  2.6249,\n",
      "          2.5170,  2.2922,  0.4972,  0.7158,  1.3747,  1.2039,  1.6296,  2.3215,\n",
      "          1.4707],\n",
      "        [ 1.2659,  0.5118,  3.4559,  1.0188,  0.9159,  2.1403,  2.4620,  2.9373,\n",
      "          0.4129,  1.5283,  1.2373, -1.4746,  2.1432,  1.1158,  2.4473,  2.3017,\n",
      "          2.2963,  2.0712,  0.4617,  0.6301,  1.1790,  1.2340,  1.4445,  2.0482,\n",
      "          1.3208],\n",
      "        [ 1.3302,  0.4045,  2.8744,  0.5810,  1.4511,  1.7210,  2.8452,  2.5928,\n",
      "          0.6628,  1.4136,  1.3885, -1.2816,  2.3630,  1.0910,  1.5169,  2.3257,\n",
      "          2.4808,  2.3283,  0.3013,  0.1962,  1.1464,  1.2732,  1.6040,  1.7968,\n",
      "          1.2460],\n",
      "        [ 1.5939,  0.2146,  3.4265,  0.8342,  0.8559,  1.3107,  2.4778,  1.9691,\n",
      "          0.9256,  1.4933,  1.6939, -1.8429,  2.1418,  1.1307,  1.9474,  2.1612,\n",
      "          2.9198,  2.1863,  1.0474,  0.4885,  1.7422,  1.0319,  1.4212,  1.6863,\n",
      "          0.8025],\n",
      "        [ 1.3243,  0.8890,  3.1220,  0.2274,  0.9151,  2.0435,  2.1365,  2.3664,\n",
      "          0.3389,  1.8633,  1.2108, -1.5189,  2.1962,  1.0445,  2.5711,  2.1880,\n",
      "          2.5775,  1.7892,  0.6720,  0.6698,  1.4405,  0.8535,  1.3432,  1.4891,\n",
      "          1.0953],\n",
      "        [ 1.4830,  0.3687,  3.2887,  0.5690,  0.8253,  1.2662,  2.4183,  2.6055,\n",
      "          0.6858,  1.9415,  1.9135, -2.0131,  2.3870,  0.9538,  2.3114,  2.1840,\n",
      "          2.1186,  2.2757,  0.5405,  0.1494,  1.4207,  1.4625,  1.5255,  1.9574,\n",
      "          1.7106],\n",
      "        [ 1.6988,  0.6821,  3.0763,  0.1714,  0.9024,  1.7268,  1.9985,  2.0253,\n",
      "          0.6879,  1.6558,  1.7978, -1.6107,  2.0492,  1.1620,  1.8826,  2.5249,\n",
      "          2.0267,  2.1245,  0.7039,  0.6908,  1.4693,  1.3673,  1.7389,  1.6418,\n",
      "          1.3524],\n",
      "        [ 1.8196,  0.4345,  3.3985,  0.3572,  0.8685,  1.6099,  2.3122,  2.1804,\n",
      "          0.4729,  1.8865,  1.5489, -1.7262,  2.0615,  1.0426,  2.1030,  2.3905,\n",
      "          2.3774,  2.5911,  0.2103,  0.6401,  1.3597,  1.2018,  1.5025,  1.9143,\n",
      "          1.1083],\n",
      "        [ 1.6642,  0.6103,  3.6782,  1.0111,  0.9796,  1.3292,  2.0721,  1.7325,\n",
      "          0.3907,  1.6020,  1.4632, -1.8864,  2.3194,  1.2654,  1.7842,  2.4646,\n",
      "          2.7804,  2.6256,  1.1682,  0.7403,  1.3110,  0.9727,  1.2182,  1.7538,\n",
      "          0.8570],\n",
      "        [ 1.1449,  0.4282,  3.5858,  0.7424,  0.9445,  2.0314,  2.7256,  2.2356,\n",
      "          0.6322,  1.6427,  1.1258, -2.1386,  2.6653,  0.9298,  2.0335,  2.5035,\n",
      "          1.7788,  2.3774,  0.1356,  0.8062,  1.0658,  1.3270,  1.5437,  2.1190,\n",
      "          1.2978],\n",
      "        [ 1.0482,  0.9019,  3.4219,  0.2215,  1.3972,  1.1907,  2.1987,  1.9166,\n",
      "          0.4851,  1.3772,  1.5101, -1.6450,  2.3187,  1.3122,  1.9154,  2.2595,\n",
      "          2.0835,  1.8561,  0.4529,  0.0803,  1.3255,  1.0571,  1.5510,  1.3427,\n",
      "          1.5661],\n",
      "        [ 1.3349,  0.1971,  3.6110,  1.0233,  1.5525,  1.6037,  2.6264,  2.6409,\n",
      "          0.6620,  1.6595,  1.4972, -1.6329,  2.1984,  0.9138,  1.8315,  2.4544,\n",
      "          2.3469,  2.2083,  0.9689,  0.4813,  1.1286,  1.2393,  1.4638,  1.7987,\n",
      "          0.7877],\n",
      "        [ 1.0801,  0.9890,  3.4415,  0.6658,  1.2534,  1.7417,  2.2906,  2.0783,\n",
      "          0.4442,  1.1034,  1.8285, -2.1027,  2.6078,  1.3684,  1.9868,  2.3576,\n",
      "          2.3811,  2.1629,  0.8750,  0.2809,  1.3991,  1.2476,  1.8490,  1.9214,\n",
      "          1.0393],\n",
      "        [ 1.6836,  0.7166,  3.6825,  0.5881,  0.6283,  1.6018,  2.1407,  2.0164,\n",
      "          0.4288,  1.3871,  1.7978, -1.8921,  2.3774,  1.3001,  1.7554,  2.2765,\n",
      "          2.3286,  2.4963,  0.1043,  0.4286,  1.5258,  1.5714,  1.4168,  2.1458,\n",
      "          1.0669],\n",
      "        [ 1.0652,  0.6362,  3.3948,  1.2995,  1.4340,  1.9274,  2.5688,  2.5211,\n",
      "          1.0497,  1.4447,  1.7126, -1.8563,  2.1214,  1.3533,  1.8592,  2.9087,\n",
      "          1.8675,  2.1079,  0.9577,  0.5095,  1.3208,  1.0589,  1.3983,  2.2986,\n",
      "          1.3635],\n",
      "        [ 1.0555,  0.6344,  3.6161,  0.9517,  1.8641,  1.4694,  2.1754,  2.4830,\n",
      "          0.4996,  1.3080,  1.4664, -1.4222,  2.0295,  1.6289,  1.7851,  2.0157,\n",
      "          2.7418,  2.3554,  0.9010,  0.5929,  1.3108,  0.9016,  1.2842,  1.7135,\n",
      "          1.4223],\n",
      "        [ 1.3698,  0.8122,  3.6585,  0.4362,  0.7670,  1.2652,  1.8014,  2.4337,\n",
      "          0.5694,  1.4923,  1.6414, -1.5976,  2.2074,  1.3590,  2.4368,  2.0783,\n",
      "          2.6303,  2.2373,  0.4580,  0.7035,  1.3730,  1.2107,  1.1587,  1.6901,\n",
      "          0.8859],\n",
      "        [ 1.5540,  0.3853,  3.5906,  1.0206,  0.7432,  1.4935,  2.5931,  2.2900,\n",
      "          0.8802,  1.6400,  1.3899, -1.5080,  2.0087,  0.8418,  1.8910,  2.4241,\n",
      "          2.8239,  2.5620,  0.1177,  0.8957,  1.5243,  1.4065,  1.2127,  2.0641,\n",
      "          1.1664],\n",
      "        [ 1.4452,  0.0264,  3.1874,  1.2317,  0.6168,  0.7991,  2.2318,  2.1375,\n",
      "          0.6972,  1.4906,  1.5153, -1.5892,  2.5398,  1.0175,  1.6025,  2.2851,\n",
      "          2.1365,  2.4665,  0.5684,  0.0812,  1.1268,  1.2497,  0.9895,  1.7594,\n",
      "          0.7946],\n",
      "        [ 1.4980,  0.5778,  3.3822,  0.8748,  0.7741,  1.3375,  2.3505,  2.4710,\n",
      "          0.6329,  1.0719,  2.1018, -1.3890,  1.8838,  0.7308,  1.6331,  2.2548,\n",
      "          2.1550,  2.4369,  0.7973,  0.8873,  1.1503,  1.4185,  1.6024,  1.9165,\n",
      "          1.5720],\n",
      "        [ 1.7214,  0.6318,  3.2632,  0.3458,  0.5034,  1.5107,  2.5321,  1.9993,\n",
      "          0.6759,  1.6440,  1.8619, -1.7651,  2.5139,  1.1930,  2.4359,  2.2661,\n",
      "          2.1325,  2.8790,  0.5827,  0.7769,  1.3715,  1.3787,  1.5711,  1.9509,\n",
      "          1.3177],\n",
      "        [ 1.2248,  0.8364,  2.9741,  0.7803,  0.9369,  2.0513,  2.6240,  2.2317,\n",
      "          0.0703,  1.7261,  1.2063, -1.8623,  2.5698,  1.0905,  2.5926,  2.6388,\n",
      "          2.0150,  2.2960,  0.0253,  0.8582,  1.7018,  1.4514,  1.8008,  2.1380,\n",
      "          1.5166],\n",
      "        [ 1.4858,  0.3618,  3.5699,  0.4825,  0.6260,  1.4967,  2.2670,  2.4405,\n",
      "          0.9636,  1.6112,  1.2428, -1.5808,  1.9673,  1.0817,  1.9920,  2.6439,\n",
      "          2.4269,  2.7430,  0.1685,  0.5856,  1.3299,  1.2887,  1.4626,  1.6318,\n",
      "          1.2043],\n",
      "        [ 1.3875,  0.7091,  3.3728,  1.3140,  1.7189,  1.7194,  2.5149,  2.3827,\n",
      "          0.8196,  1.1126,  1.7044, -1.4378,  2.3983,  1.3658,  2.0083,  2.5940,\n",
      "          1.8786,  2.0485,  0.5424,  0.3697,  1.4855,  1.2394,  1.4097,  2.0842,\n",
      "          1.4873],\n",
      "        [ 1.7707,  0.3738,  3.5974,  0.8984,  0.7975,  1.4555,  2.4665,  2.2093,\n",
      "         -0.1245,  1.0925,  1.8057, -2.2169,  2.3908,  1.2959,  1.4910,  2.3325,\n",
      "          2.5042,  2.5299,  0.6370,  0.2120,  1.4276,  1.0570,  1.0942,  1.6757,\n",
      "          0.8052],\n",
      "        [ 1.5476,  0.7484,  3.3158,  0.4804,  1.7143,  1.8944,  2.2268,  2.2135,\n",
      "          0.5490,  1.4292,  1.5875, -2.0428,  2.2591,  0.7346,  1.8609,  2.2434,\n",
      "          2.1867,  2.8232,  0.5231,  0.2005,  1.7756,  1.8784,  1.7869,  1.2451,\n",
      "          1.2524],\n",
      "        [ 1.3755,  0.5437,  3.2227,  0.7368,  0.8140,  1.6044,  2.6316,  2.4796,\n",
      "          0.8027,  1.7824,  1.6966, -1.2194,  2.2674,  1.1752,  2.3111,  2.5184,\n",
      "          2.8020,  2.1615,  0.2493,  0.9517,  1.6338,  1.4567,  1.4771,  2.3266,\n",
      "          1.4666],\n",
      "        [ 1.5007,  0.4074,  3.0080,  0.8904,  1.3748,  0.9492,  2.5685,  1.6599,\n",
      "          0.6161,  1.3900,  2.0238, -1.3948,  2.3799,  1.1902,  2.0253,  2.3755,\n",
      "          2.1155,  2.1332,  0.4101,  0.2220,  1.2891,  1.1981,  1.4281,  1.8937,\n",
      "          1.5039],\n",
      "        [ 1.7939,  0.6068,  3.3429,  0.5341,  0.8250,  1.5831,  2.2579,  2.2594,\n",
      "          0.5657,  2.0884,  1.4937, -1.6314,  2.3320,  1.2987,  2.1894,  2.1513,\n",
      "          2.1709,  2.7564,  0.1820,  0.8886,  1.4563,  1.0040,  1.3437,  2.1285,\n",
      "          1.1484]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.5984, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.0663, -0.2745,  2.7955,  1.1325,  1.7645,  1.1189,  2.0275,  2.1348,\n",
      "          0.4233,  0.2628,  1.5216, -1.5551,  2.0930,  1.6085,  2.8492,  2.9484,\n",
      "          2.4017,  2.2354,  0.7012,  1.2318,  1.3568,  1.5124,  0.8086,  1.6583,\n",
      "          1.5292],\n",
      "        [ 1.7842,  0.6097,  3.2504,  0.9729,  0.7659,  1.4256,  1.3432,  2.0765,\n",
      "          0.6205,  0.7215,  1.6150, -1.2932,  2.2933,  1.1883,  3.1308,  2.9225,\n",
      "          2.4307,  2.4323,  0.6654,  0.9868,  1.4177,  1.2407,  1.0573,  2.2456,\n",
      "          1.7931],\n",
      "        [ 1.5686,  0.1274,  2.9676,  1.1666,  0.8689,  1.4752,  1.2077,  2.0089,\n",
      "          1.0300,  0.7955,  2.0012, -1.0116,  1.7826,  1.3598,  3.0924,  3.1251,\n",
      "          2.2391,  2.4090,  0.9035,  1.3476,  1.7322,  1.2400,  1.3501,  2.3444,\n",
      "          1.8695],\n",
      "        [ 1.2955,  0.2635,  2.4280,  0.9947,  1.8528,  1.7179,  1.8235,  1.9432,\n",
      "          0.6123,  0.4464,  1.2831, -1.5021,  2.3328,  1.4814,  2.4412,  3.0745,\n",
      "          2.1402,  2.1651,  1.1207,  1.0417,  1.6228,  1.3379,  0.9942,  1.9769,\n",
      "          1.9520],\n",
      "        [ 2.0116,  0.3490,  3.1465,  1.1556,  1.3561,  0.9405,  1.0963,  1.9576,\n",
      "          0.3771,  0.7200,  1.3703, -0.9811,  2.3875,  1.7050,  2.6421,  2.5819,\n",
      "          2.1011,  2.1185,  0.3066,  1.0111,  1.0508,  1.1394,  0.4771,  1.9274,\n",
      "          1.6892],\n",
      "        [ 1.5539,  0.7012,  3.2255,  1.0592,  1.7306,  1.0023,  2.1834,  2.0092,\n",
      "          0.3715,  0.5749,  1.6422, -1.0231,  1.9632,  1.4469,  2.8458,  2.8211,\n",
      "          2.4236,  2.5934,  0.5715,  1.0689,  1.4639,  1.5107,  1.0728,  2.0583,\n",
      "          1.5597],\n",
      "        [ 1.4765,  0.3993,  3.3344,  1.2449,  1.2511,  0.7905,  1.4028,  1.8245,\n",
      "          0.4479,  0.0346,  1.5575, -1.3931,  2.3346,  1.9141,  2.3845,  2.8295,\n",
      "          2.6190,  2.1998,  0.8131,  0.9294,  1.4090,  1.3402,  1.0032,  2.2188,\n",
      "          2.1390],\n",
      "        [ 1.5240, -0.1966,  3.5104,  1.2181,  1.0440,  1.3547,  1.6774,  1.9042,\n",
      "          0.6452,  0.6970,  1.3442, -1.2060,  2.0293,  0.9306,  2.3688,  2.7684,\n",
      "          2.3691,  2.0999,  1.2026,  1.3758,  1.1746,  1.2094,  1.1183,  1.9858,\n",
      "          1.6328],\n",
      "        [ 1.8372, -0.0635,  3.3269,  0.8521,  1.1002,  1.7973,  1.4949,  1.9846,\n",
      "          0.3582,  0.6637,  1.1869, -1.5055,  2.2600,  1.3124,  2.8823,  2.6791,\n",
      "          2.7605,  2.2529,  1.1943,  0.8352,  1.7041,  1.2177,  0.7643,  1.8810,\n",
      "          1.6779],\n",
      "        [ 1.6224,  0.3598,  3.3165,  1.4951,  0.9108,  1.0775,  1.1809,  1.8157,\n",
      "          1.0095,  0.5716,  1.6834, -1.5886,  2.1525,  1.5291,  2.8215,  2.9309,\n",
      "          2.0168,  2.4737,  1.0293,  0.9691,  1.5125,  1.1767,  0.6009,  2.1162,\n",
      "          1.6657],\n",
      "        [ 1.7394,  0.2509,  2.6337,  1.2457,  1.4370,  0.5317,  1.8144,  2.3485,\n",
      "          0.4130,  1.1003,  2.0893, -1.2631,  2.0971,  1.7958,  2.3503,  2.5390,\n",
      "          2.6355,  2.4904,  0.8344,  0.9403,  1.5091,  0.8240,  1.1382,  2.3000,\n",
      "          1.6349],\n",
      "        [ 1.7835,  0.3774,  2.8275,  1.0313,  0.9790,  1.5240,  1.1844,  1.8712,\n",
      "          0.3428,  0.5463,  1.9177, -1.5422,  2.0328,  1.7825,  2.7107,  3.1835,\n",
      "          2.5211,  2.4011,  0.7919,  1.0339,  1.4112,  1.3271,  0.8779,  2.2669,\n",
      "          1.9810],\n",
      "        [ 1.2959,  0.2368,  2.7583,  1.0084,  1.2011,  1.3018,  1.4153,  1.4741,\n",
      "          0.4568,  0.5449,  1.4504, -1.3586,  2.0204,  1.6287,  2.5412,  2.4813,\n",
      "          2.5751,  2.5536,  0.8780,  0.4905,  1.6839,  1.1306,  1.0760,  1.8609,\n",
      "          1.6451],\n",
      "        [ 1.8955,  0.3979,  3.2151,  1.1191,  1.2423,  1.2413,  1.6359,  2.2056,\n",
      "          0.3558,  0.1968,  1.6389, -1.3083,  2.0776,  1.6667,  2.7630,  2.7046,\n",
      "          2.7562,  2.5393,  0.7461,  0.9593,  1.5166,  1.1811,  0.7374,  1.9321,\n",
      "          1.5053],\n",
      "        [ 1.8714,  0.7507,  3.0701,  1.0504,  0.6348,  1.2910,  1.2111,  2.2151,\n",
      "          0.6867,  0.7282,  1.6063, -1.1858,  2.1379,  1.7818,  2.7419,  2.2898,\n",
      "          2.5472,  2.2743,  0.7760,  1.0841,  1.3516,  1.3102,  0.8260,  2.1612,\n",
      "          2.0202],\n",
      "        [ 2.1043, -0.0222,  3.0431,  0.6090,  0.6575,  1.1564,  1.2956,  1.6386,\n",
      "          0.3515,  0.7223,  1.6306, -1.3879,  1.9873,  1.2043,  3.1150,  2.5131,\n",
      "          2.8137,  2.3639,  0.7619,  0.9262,  1.7208,  1.3023,  1.3557,  2.1379,\n",
      "          1.1991],\n",
      "        [ 1.7732,  0.0648,  3.0692,  0.6293,  0.7723,  0.9945,  1.1310,  2.2358,\n",
      "          0.5618,  0.3984,  1.6294, -1.3930,  1.8569,  1.3716,  2.5947,  2.6548,\n",
      "          2.7464,  2.6132,  0.9847,  0.7693,  1.3215,  1.2989,  1.3454,  1.8304,\n",
      "          1.6072],\n",
      "        [ 1.6577,  0.6405,  2.7362,  0.9288,  1.9287,  1.0674,  1.6009,  1.8607,\n",
      "          0.6554,  0.1130,  1.5868, -1.3467,  2.3816,  1.5351,  2.5905,  2.7624,\n",
      "          2.4141,  2.2433,  1.1544,  0.9323,  1.5498,  1.3635,  0.7666,  2.1142,\n",
      "          1.8787],\n",
      "        [ 1.3378,  0.0421,  3.0414,  1.5955,  1.4252,  0.7082,  1.4888,  1.8564,\n",
      "          0.3581,  0.3489,  1.5338, -1.6003,  2.2562,  1.7740,  2.7553,  2.5780,\n",
      "          2.3678,  2.4317,  0.8089,  0.9638,  1.2029,  1.4795,  1.1378,  1.7612,\n",
      "          1.5456],\n",
      "        [ 1.6796, -0.2204,  3.0748,  1.0147,  1.3131,  1.4572,  1.3158,  1.5035,\n",
      "          0.9889,  0.7722,  1.7304, -1.8760,  2.0338,  1.1112,  2.7711,  2.9492,\n",
      "          2.4098,  2.0961,  0.6681,  0.5292,  1.5449,  1.2129,  1.3175,  2.1354,\n",
      "          1.5682],\n",
      "        [ 1.8692, -0.0341,  3.1413,  1.1148,  0.6423,  0.8502,  1.6096,  2.4541,\n",
      "          0.3291,  0.6447,  2.0852, -1.6998,  2.3356,  1.5554,  2.9788,  2.9820,\n",
      "          3.3761,  2.5197,  0.7355,  0.6428,  1.5263,  1.4377,  1.2248,  1.7819,\n",
      "          1.5259],\n",
      "        [ 1.6842,  0.4983,  2.9818,  1.2192,  0.9544,  0.7721,  1.4160,  2.5804,\n",
      "          0.5877,  0.4716,  1.6486, -1.2179,  1.8263,  1.5491,  2.8813,  2.3747,\n",
      "          2.1708,  2.5322,  0.8246,  0.9774,  1.2627,  1.3630,  1.0850,  2.0925,\n",
      "          1.6624],\n",
      "        [ 1.9333,  0.1881,  3.1252,  0.9297,  1.2596,  1.1265,  1.3836,  1.9689,\n",
      "          0.5157,  0.2647,  1.7026, -1.6106,  2.0573,  1.3657,  2.7763,  2.6002,\n",
      "          2.7193,  2.6577,  1.2943,  0.6705,  1.7616,  1.2410,  0.5861,  1.9124,\n",
      "          1.9881],\n",
      "        [ 1.6305,  0.4285,  2.9373,  0.9882,  1.1603,  0.8729,  1.2806,  2.2199,\n",
      "          0.5324,  0.1883,  1.1025, -1.4633,  1.9959,  1.3166,  2.6129,  2.8544,\n",
      "          2.6254,  2.2759,  1.0725,  0.8562,  1.6837,  1.4017,  0.6024,  2.0801,\n",
      "          1.7478],\n",
      "        [ 2.1382,  0.0319,  3.3614,  1.1176,  0.8835,  0.8398,  1.2217,  2.0456,\n",
      "          0.3733,  0.2485,  1.6879, -1.7464,  2.0783,  1.3199,  2.4354,  2.7282,\n",
      "          2.8547,  2.4335,  0.8435,  1.1316,  1.2632,  1.2362,  0.7971,  1.5906,\n",
      "          1.1529],\n",
      "        [ 1.6282, -0.0971,  2.7623,  1.2407,  1.2033,  0.7667,  1.8943,  1.9299,\n",
      "          0.5776,  0.8102,  1.8471, -1.2870,  1.9664,  1.3534,  2.5505,  2.5670,\n",
      "          2.0659,  2.4693,  1.0582,  1.0486,  1.5120,  1.5623,  0.8356,  2.3590,\n",
      "          1.6013],\n",
      "        [ 1.5783, -0.0072,  3.1659,  0.9819,  1.1768,  0.6208,  1.3351,  2.0986,\n",
      "          0.1256,  0.4166,  2.0947, -1.2758,  2.0955,  1.7260,  2.6135,  2.8755,\n",
      "          2.4712,  2.2185,  1.2973,  0.5972,  1.3397,  1.4020,  1.1410,  2.0617,\n",
      "          1.9946],\n",
      "        [ 1.5489,  0.6899,  3.1741,  1.2313,  0.5876,  1.4620,  1.6858,  2.0705,\n",
      "          0.6511,  0.6839,  1.0823, -1.2934,  2.2129,  1.4148,  2.7248,  3.0940,\n",
      "          2.5226,  2.2316,  0.4302,  1.9024,  1.5395,  0.8664,  0.9596,  2.0812,\n",
      "          1.6171],\n",
      "        [ 1.5139, -0.1725,  3.3093,  1.4188,  1.5190,  1.0886,  1.8387,  2.3319,\n",
      "          0.3096,  0.6989,  1.7782, -1.6342,  2.5967,  1.4053,  2.6328,  2.8224,\n",
      "          2.2097,  2.4047,  0.9258,  1.0386,  1.6631,  1.2779,  1.0110,  1.9133,\n",
      "          1.8557],\n",
      "        [ 1.5534, -0.0777,  3.1655,  1.0484,  0.9854,  0.3511,  1.3668,  2.1675,\n",
      "          0.6739,  0.1030,  1.6921, -1.4102,  2.2889,  1.7142,  2.7331,  2.2989,\n",
      "          2.8777,  2.4618,  0.9427,  0.7704,  1.2045,  0.9404,  0.5785,  1.5388,\n",
      "          1.4966],\n",
      "        [ 1.6809, -0.2384,  2.8095,  1.3134,  1.1438,  0.6985,  0.9001,  2.3037,\n",
      "          0.3241,  0.4660,  1.7711, -1.2397,  1.5372,  1.6615,  2.2889,  2.9771,\n",
      "          2.9012,  2.1568,  0.7555,  0.7544,  1.2046,  1.2874,  0.8152,  1.5493,\n",
      "          1.1980],\n",
      "        [ 1.7154,  0.2560,  3.3963,  1.1761,  0.9840,  0.7012,  1.5083,  2.2631,\n",
      "          0.2710,  0.3548,  1.6111, -1.2187,  2.1061,  1.5248,  2.5276,  2.6351,\n",
      "          2.9577,  2.4548,  1.0520,  0.9637,  1.1702,  1.0172,  0.6315,  1.9493,\n",
      "          1.6942]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.9579, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.8547e+00, -6.7010e-01,  2.8379e+00,  1.5896e+00,  1.3397e+00,\n",
      "          7.6949e-01,  1.2708e+00,  1.5238e+00,  3.6231e-01, -3.9882e-02,\n",
      "          1.7594e+00, -3.2900e-01,  1.9889e+00,  1.6962e+00,  2.8489e+00,\n",
      "          2.8647e+00,  2.5135e+00,  3.6794e+00,  1.1471e+00,  1.8035e+00,\n",
      "          1.3480e+00,  1.7311e+00,  1.5224e-01,  2.4162e+00,  1.6701e+00],\n",
      "        [ 2.4307e+00,  2.4196e-01,  2.8845e+00,  1.6118e+00,  1.2417e+00,\n",
      "          1.2086e+00,  3.4087e-01,  1.4974e+00,  1.6514e-01,  3.2623e-02,\n",
      "          1.5794e+00, -5.4547e-01,  1.5309e+00,  1.4554e+00,  3.1524e+00,\n",
      "          2.8125e+00,  2.1623e+00,  3.0306e+00,  9.6016e-01,  1.4771e+00,\n",
      "          1.1918e+00,  2.0536e+00,  1.2279e-01,  1.8868e+00,  1.8594e+00],\n",
      "        [ 2.5655e+00, -5.3993e-01,  2.4926e+00,  1.7779e+00,  1.2613e+00,\n",
      "          8.2896e-01,  9.9144e-01,  1.4258e+00,  3.7533e-01, -9.7570e-01,\n",
      "          1.6655e+00, -6.6547e-01,  1.8749e+00,  1.6372e+00,  2.8492e+00,\n",
      "          2.6263e+00,  2.1299e+00,  2.9049e+00,  1.2806e+00,  1.7843e+00,\n",
      "          1.7292e+00,  1.6046e+00, -2.7588e-02,  1.6107e+00,  2.1127e+00],\n",
      "        [ 2.4842e+00, -5.2195e-01,  2.1706e+00,  1.8177e+00,  1.1752e+00,\n",
      "          6.6304e-01,  4.1226e-01,  1.6416e+00,  9.0334e-01, -2.7389e-01,\n",
      "          1.4147e+00, -3.0186e-01,  1.5276e+00,  1.5738e+00,  2.9916e+00,\n",
      "          2.6430e+00,  2.3075e+00,  2.9000e+00,  6.1150e-01,  1.6203e+00,\n",
      "          1.4016e+00,  1.9935e+00,  4.3002e-01,  2.2262e+00,  2.1861e+00],\n",
      "        [ 2.2136e+00, -3.0437e-01,  2.6419e+00,  2.1123e+00,  1.2897e+00,\n",
      "          7.0541e-01,  1.2636e+00,  1.7149e+00,  6.9192e-01,  1.6178e-01,\n",
      "          1.5980e+00, -9.8213e-03,  1.0989e+00,  1.9444e+00,  2.7299e+00,\n",
      "          2.2836e+00,  1.4127e+00,  3.3524e+00,  1.6264e+00,  1.9333e+00,\n",
      "          9.6318e-01,  1.5506e+00,  7.2325e-01,  2.3710e+00,  1.8281e+00],\n",
      "        [ 2.0503e+00, -6.8871e-01,  2.2099e+00,  1.7252e+00,  1.1200e+00,\n",
      "          7.5414e-01,  6.1248e-01,  1.4304e+00,  5.2960e-01,  4.8845e-01,\n",
      "          1.7061e+00, -4.5685e-01,  1.9975e+00,  1.7772e+00,  2.5957e+00,\n",
      "          2.6212e+00,  2.0696e+00,  2.5198e+00,  1.3708e+00,  1.7335e+00,\n",
      "          6.5979e-01,  1.9088e+00,  6.4641e-01,  2.3790e+00,  1.9127e+00],\n",
      "        [ 2.6365e+00,  7.1120e-02,  2.9314e+00,  1.4445e+00,  1.3483e+00,\n",
      "          8.8596e-01,  7.8239e-01,  1.6365e+00,  8.2381e-01, -3.0182e-01,\n",
      "          1.4622e+00, -7.7307e-01,  1.6041e+00,  1.6366e+00,  3.1194e+00,\n",
      "          2.1990e+00,  1.6936e+00,  2.9869e+00,  1.2253e+00,  1.5170e+00,\n",
      "          1.8375e+00,  1.4559e+00,  6.5390e-01,  1.9576e+00,  1.8628e+00],\n",
      "        [ 2.3637e+00, -4.0449e-02,  2.7216e+00,  1.3256e+00,  1.8868e+00,\n",
      "          6.0709e-01,  5.0548e-01,  1.8727e+00,  6.2358e-01, -4.3224e-01,\n",
      "          1.4941e+00, -3.2826e-01,  1.9896e+00,  1.8882e+00,  2.5799e+00,\n",
      "          2.6042e+00,  1.9438e+00,  3.4107e+00,  1.2528e+00,  1.4651e+00,\n",
      "          1.4883e+00,  1.4903e+00, -7.0854e-02,  1.9797e+00,  2.0022e+00],\n",
      "        [ 2.4812e+00, -5.2499e-02,  2.9969e+00,  1.4352e+00,  1.3396e+00,\n",
      "         -2.0100e-03,  1.0124e+00,  1.6699e+00,  2.1461e-01, -6.9491e-01,\n",
      "          1.5216e+00, -7.2895e-01,  1.6340e+00,  1.5971e+00,  2.3386e+00,\n",
      "          2.4079e+00,  2.8790e+00,  3.3968e+00,  1.3259e+00,  1.5382e+00,\n",
      "          1.3505e+00,  1.4128e+00, -1.1507e-01,  1.1876e+00,  2.2334e+00],\n",
      "        [ 2.1140e+00, -2.8247e-01,  3.2473e+00,  1.8933e+00,  1.0066e+00,\n",
      "          3.0122e-01,  1.3460e+00,  2.0481e+00,  5.0166e-01, -4.4991e-01,\n",
      "          1.8695e+00, -9.7028e-01,  1.6547e+00,  2.3072e+00,  2.8458e+00,\n",
      "          1.9924e+00,  2.2040e+00,  3.2440e+00,  1.9974e+00,  1.2286e+00,\n",
      "          1.4527e+00,  1.7094e+00,  3.2448e-01,  1.8380e+00,  1.8258e+00],\n",
      "        [ 2.3349e+00, -6.9635e-01,  2.5552e+00,  1.5891e+00,  1.3165e+00,\n",
      "          1.2683e-01,  5.1505e-01,  1.7551e+00,  9.2997e-01, -8.0560e-01,\n",
      "          1.7179e+00, -4.3590e-01,  2.1071e+00,  2.0008e+00,  2.6465e+00,\n",
      "          2.1837e+00,  2.0952e+00,  2.7022e+00,  1.5713e+00,  1.1912e+00,\n",
      "          1.3574e+00,  1.0698e+00,  4.2126e-02,  1.7760e+00,  1.5472e+00],\n",
      "        [ 2.4907e+00, -1.3516e-01,  3.0372e+00,  1.6682e+00,  1.6304e+00,\n",
      "          1.1843e-01,  8.2244e-01,  1.7541e+00,  2.5751e-01, -7.9067e-01,\n",
      "          1.4745e+00, -5.9781e-01,  1.7267e+00,  2.0586e+00,  2.5988e+00,\n",
      "          2.4719e+00,  2.5094e+00,  3.4742e+00,  1.4217e+00,  1.1471e+00,\n",
      "          1.1317e+00,  1.9006e+00,  3.8947e-01,  1.5602e+00,  1.9511e+00],\n",
      "        [ 2.5468e+00, -2.6184e-01,  2.8801e+00,  1.4415e+00,  1.1698e+00,\n",
      "          9.9168e-01,  8.1422e-01,  1.8087e+00,  4.5564e-01,  1.9000e-01,\n",
      "          1.9544e+00, -3.5527e-01,  1.5737e+00,  2.2967e+00,  3.2374e+00,\n",
      "          2.1480e+00,  2.4439e+00,  3.3059e+00,  1.3137e+00,  1.8600e+00,\n",
      "          1.6459e+00,  1.5090e+00,  2.8278e-02,  1.6868e+00,  1.5489e+00],\n",
      "        [ 2.4332e+00, -2.7583e-01,  2.4106e+00,  1.5247e+00,  6.8784e-01,\n",
      "          7.8061e-01,  6.6457e-01,  1.8619e+00,  8.0839e-01, -2.5235e-01,\n",
      "          1.6878e+00, -3.0120e-01,  1.8151e+00,  1.8661e+00,  2.8236e+00,\n",
      "          2.4357e+00,  2.1774e+00,  2.9907e+00,  1.4683e+00,  1.2080e+00,\n",
      "          1.3497e+00,  1.5447e+00,  7.5268e-01,  1.9324e+00,  1.9695e+00],\n",
      "        [ 2.6136e+00, -2.5878e-01,  2.6008e+00,  1.4078e+00,  7.3969e-01,\n",
      "          3.8571e-01,  5.2160e-01,  1.4649e+00,  7.1443e-01, -5.6208e-01,\n",
      "          1.8249e+00, -2.7778e-01,  1.4527e+00,  1.7963e+00,  2.7792e+00,\n",
      "          1.7771e+00,  2.9126e+00,  2.6023e+00,  9.9147e-01,  1.4080e+00,\n",
      "          1.7787e+00,  1.3879e+00,  4.3721e-02,  1.6378e+00,  2.1074e+00],\n",
      "        [ 2.9096e+00, -4.1856e-01,  2.6224e+00,  1.5820e+00,  1.1541e+00,\n",
      "          9.2771e-01,  7.8391e-01,  2.0138e+00,  5.7593e-01, -1.5910e-01,\n",
      "          1.7249e+00, -3.5132e-01,  1.6672e+00,  1.5161e+00,  2.6401e+00,\n",
      "          2.5797e+00,  2.3789e+00,  3.0744e+00,  1.0555e+00,  1.5683e+00,\n",
      "          1.1978e+00,  1.7199e+00,  3.6993e-01,  1.7524e+00,  2.3473e+00],\n",
      "        [ 2.6100e+00, -1.1933e-01,  3.1784e+00,  1.2704e+00,  8.1695e-01,\n",
      "          5.4144e-01,  3.9046e-01,  1.8476e+00,  3.6861e-01, -4.6614e-01,\n",
      "          1.6949e+00, -4.9158e-01,  1.6238e+00,  1.4508e+00,  2.7562e+00,\n",
      "          2.6579e+00,  2.4141e+00,  3.1883e+00,  1.5763e+00,  1.7564e+00,\n",
      "          1.4341e+00,  1.7350e+00,  7.0434e-01,  1.8069e+00,  1.9817e+00],\n",
      "        [ 2.4753e+00, -1.6215e-01,  2.6866e+00,  1.5675e+00,  1.2416e+00,\n",
      "          7.9093e-01,  8.7391e-01,  1.8809e+00,  2.7640e-01, -3.7136e-01,\n",
      "          1.7488e+00, -8.3994e-01,  1.8178e+00,  1.8658e+00,  3.0577e+00,\n",
      "          2.1014e+00,  2.1501e+00,  3.1204e+00,  1.2391e+00,  1.6373e+00,\n",
      "          1.0081e+00,  1.7186e+00,  3.7575e-02,  2.0347e+00,  2.1255e+00],\n",
      "        [ 2.7361e+00, -1.8122e-01,  2.4281e+00,  1.7334e+00,  1.0388e+00,\n",
      "          6.9610e-01,  9.6224e-01,  1.6386e+00,  6.7070e-01, -3.7689e-01,\n",
      "          1.4145e+00, -7.6925e-02,  1.8613e+00,  1.8213e+00,  2.6780e+00,\n",
      "          2.4413e+00,  2.2294e+00,  3.1972e+00,  1.0569e+00,  1.4462e+00,\n",
      "          1.1280e+00,  1.5009e+00,  1.7655e-01,  2.1131e+00,  2.2871e+00],\n",
      "        [ 2.4092e+00, -5.7681e-01,  2.5295e+00,  1.5163e+00,  1.3612e+00,\n",
      "          3.5200e-01,  4.1346e-01,  1.6488e+00,  1.7106e-01, -7.9257e-01,\n",
      "          1.5160e+00, -3.2383e-01,  1.9548e+00,  1.9812e+00,  2.8028e+00,\n",
      "          2.4311e+00,  2.7401e+00,  2.7744e+00,  1.6460e+00,  9.7146e-01,\n",
      "          1.2301e+00,  1.1318e+00,  1.1093e-02,  1.8084e+00,  1.8981e+00],\n",
      "        [ 2.5103e+00, -3.1129e-01,  2.2314e+00,  1.6502e+00,  1.5482e+00,\n",
      "          6.1666e-01,  1.0972e+00,  1.8260e+00,  3.9412e-01, -5.2604e-01,\n",
      "          1.6404e+00, -2.4515e-01,  1.7535e+00,  2.3102e+00,  2.7765e+00,\n",
      "          2.5499e+00,  2.2091e+00,  3.1416e+00,  1.3682e+00,  1.6544e+00,\n",
      "          1.2485e+00,  1.6475e+00,  2.3920e-01,  1.7921e+00,  2.1365e+00],\n",
      "        [ 2.2599e+00, -4.2440e-01,  2.7303e+00,  1.6114e+00,  1.2377e+00,\n",
      "          1.9332e-01,  6.5925e-01,  1.6262e+00,  5.4946e-01, -6.5112e-01,\n",
      "          2.0699e+00, -2.3633e-01,  1.6213e+00,  2.1815e+00,  2.2912e+00,\n",
      "          2.3084e+00,  2.3615e+00,  3.2972e+00,  1.0113e+00,  1.7452e+00,\n",
      "          1.0444e+00,  1.6360e+00,  2.7233e-01,  1.5918e+00,  2.1287e+00],\n",
      "        [ 2.3694e+00, -1.0583e-01,  2.6697e+00,  1.8451e+00,  1.0814e+00,\n",
      "          1.2127e+00,  1.2119e+00,  1.8526e+00,  5.4046e-01, -3.2983e-01,\n",
      "          1.3190e+00, -5.2682e-01,  1.5127e+00,  1.9804e+00,  3.2844e+00,\n",
      "          2.5964e+00,  1.8143e+00,  3.0143e+00,  8.3482e-01,  1.9870e+00,\n",
      "          1.7025e+00,  1.7088e+00,  1.3669e-01,  2.0464e+00,  2.2042e+00],\n",
      "        [ 2.4050e+00, -2.1708e-01,  2.9949e+00,  1.5811e+00,  1.2221e+00,\n",
      "          5.8328e-01,  8.8540e-01,  1.4637e+00,  8.9274e-02, -5.1950e-01,\n",
      "          1.9092e+00, -6.7819e-01,  1.7032e+00,  1.7117e+00,  2.6594e+00,\n",
      "          2.6464e+00,  2.2585e+00,  3.2368e+00,  9.1815e-01,  1.5383e+00,\n",
      "          1.3348e+00,  1.1387e+00,  2.7337e-01,  1.8784e+00,  2.3985e+00],\n",
      "        [ 2.7699e+00, -3.4855e-01,  2.5711e+00,  1.4187e+00,  6.1575e-01,\n",
      "          7.2834e-01,  6.4531e-01,  1.5612e+00,  4.0316e-01,  8.1983e-02,\n",
      "          1.8936e+00, -1.8711e-01,  1.4379e+00,  1.7626e+00,  3.0895e+00,\n",
      "          2.2345e+00,  2.3754e+00,  3.5822e+00,  1.2392e+00,  1.9461e+00,\n",
      "          1.1733e+00,  1.3437e+00,  5.9098e-02,  1.6775e+00,  2.1514e+00],\n",
      "        [ 2.3467e+00, -3.6281e-01,  2.5062e+00,  1.5922e+00,  1.3531e+00,\n",
      "          9.7523e-01,  6.6309e-01,  1.6325e+00,  1.0175e+00, -8.3700e-02,\n",
      "          1.6650e+00, -2.4991e-01,  1.7385e+00,  1.9001e+00,  2.8359e+00,\n",
      "          2.4062e+00,  2.3527e+00,  2.2278e+00,  1.2437e+00,  1.9198e+00,\n",
      "          1.8069e+00,  1.6639e+00, -2.3264e-01,  1.8499e+00,  2.2442e+00],\n",
      "        [ 2.1670e+00,  6.6772e-02,  2.5796e+00,  1.5133e+00,  1.3088e+00,\n",
      "          8.0818e-01,  8.0154e-01,  1.6471e+00,  4.6630e-01, -4.4843e-01,\n",
      "          1.5839e+00,  6.4156e-02,  2.0236e+00,  1.6767e+00,  2.5902e+00,\n",
      "          2.4503e+00,  2.4287e+00,  2.5455e+00,  9.5762e-01,  1.6175e+00,\n",
      "          1.8236e+00,  1.4116e+00,  2.9587e-01,  1.8235e+00,  1.7344e+00],\n",
      "        [ 2.2591e+00, -2.5603e-01,  2.8378e+00,  1.3517e+00,  6.7422e-01,\n",
      "          7.9868e-01,  3.6777e-01,  1.5757e+00,  6.6816e-01, -2.9424e-01,\n",
      "          1.5557e+00, -7.7778e-01,  1.6187e+00,  2.1508e+00,  2.9537e+00,\n",
      "          1.9043e+00,  2.0190e+00,  3.1773e+00,  9.6421e-01,  1.8394e+00,\n",
      "          1.4378e+00,  1.9178e+00,  2.0559e-01,  1.9207e+00,  1.7950e+00],\n",
      "        [ 2.1350e+00, -1.1818e-01,  2.7220e+00,  1.4334e+00,  1.2884e+00,\n",
      "          1.1406e+00,  8.2661e-01,  1.2479e+00,  5.1099e-01, -1.9006e-01,\n",
      "          1.4598e+00, -8.0498e-01,  2.1095e+00,  1.9101e+00,  2.9620e+00,\n",
      "          2.7695e+00,  1.8660e+00,  2.6233e+00,  1.2921e+00,  1.2792e+00,\n",
      "          8.7613e-01,  1.3032e+00, -7.3583e-02,  1.9510e+00,  2.1148e+00],\n",
      "        [ 2.2640e+00,  1.8835e-02,  3.1226e+00,  1.0420e+00,  1.2976e+00,\n",
      "          8.6205e-01,  9.1865e-01,  1.9001e+00,  3.0842e-01, -5.8948e-01,\n",
      "          1.3977e+00, -6.8407e-01,  1.8998e+00,  1.7709e+00,  2.9367e+00,\n",
      "          2.6971e+00,  2.3034e+00,  3.0547e+00,  1.1654e+00,  1.4527e+00,\n",
      "          1.6010e+00,  1.5816e+00,  8.6272e-02,  1.4945e+00,  2.0871e+00],\n",
      "        [ 2.1069e+00,  5.5174e-01,  2.4104e+00,  1.4980e+00,  1.3574e+00,\n",
      "          1.5091e+00,  1.2052e+00,  1.3077e+00,  6.7424e-01, -8.1285e-02,\n",
      "          1.4612e+00,  1.0193e-02,  1.7992e+00,  1.7745e+00,  3.1637e+00,\n",
      "          2.1935e+00,  1.9693e+00,  2.8497e+00,  8.1687e-01,  2.2663e+00,\n",
      "          1.3261e+00,  1.6645e+00,  4.1465e-01,  2.2215e+00,  1.4096e+00],\n",
      "        [ 2.4254e+00, -1.3828e-02,  2.5770e+00,  1.4273e+00,  1.3883e+00,\n",
      "          1.2087e+00,  7.7476e-01,  1.8795e+00,  4.5924e-01, -6.8923e-02,\n",
      "          1.7146e+00, -8.1238e-01,  1.6143e+00,  1.6690e+00,  3.0281e+00,\n",
      "          2.8375e+00,  1.6197e+00,  2.4116e+00,  1.2299e+00,  1.2766e+00,\n",
      "          1.3843e+00,  1.7684e+00,  5.0254e-01,  2.2326e+00,  2.1251e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.4749, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.7223e+00, -2.5721e-03,  1.9851e+00,  2.0175e+00,  8.1354e-01,\n",
      "          9.3877e-01,  1.6535e-01,  1.3915e+00,  7.5004e-01, -2.1273e-02,\n",
      "          1.4852e+00,  7.5823e-01,  1.3306e+00,  2.2739e+00,  2.3687e+00,\n",
      "          1.6226e+00,  2.2377e+00,  3.0238e+00,  1.4378e+00,  1.6906e+00,\n",
      "          1.7310e+00,  1.8656e+00,  1.9054e-01,  1.6766e+00,  1.9731e+00],\n",
      "        [ 2.5410e+00, -5.1211e-01,  2.3476e+00,  1.8303e+00,  8.7852e-01,\n",
      "          1.0579e+00,  8.2634e-01,  1.5028e+00,  3.9679e-01, -8.8332e-01,\n",
      "          2.0357e+00,  2.9317e-01,  1.6187e+00,  2.1552e+00,  2.1411e+00,\n",
      "          2.2437e+00,  2.5247e+00,  2.8851e+00,  1.6143e+00,  2.0312e+00,\n",
      "          1.6058e+00,  1.6648e+00, -9.5427e-02,  1.4314e+00,  2.2147e+00],\n",
      "        [ 2.8810e+00, -1.0281e-01,  1.8634e+00,  1.8887e+00,  9.2815e-01,\n",
      "          1.1008e+00,  3.2088e-02,  1.0432e+00,  4.1542e-01, -7.9847e-01,\n",
      "          1.7251e+00,  5.8878e-01,  1.6450e+00,  1.5464e+00,  2.5869e+00,\n",
      "          2.1811e+00,  2.2249e+00,  2.9011e+00,  1.6090e+00,  1.6324e+00,\n",
      "          2.1112e+00,  1.7490e+00,  2.0064e-01,  1.7444e+00,  2.4252e+00],\n",
      "        [ 2.6072e+00,  2.0042e-01,  2.0294e+00,  2.1629e+00,  1.6234e+00,\n",
      "          6.1610e-01,  6.1856e-01,  1.5839e+00,  6.9045e-01, -4.0229e-01,\n",
      "          1.7172e+00,  2.8221e-01,  1.3676e+00,  1.9462e+00,  2.5850e+00,\n",
      "          1.9461e+00,  2.0513e+00,  2.6458e+00,  2.0768e+00,  1.5124e+00,\n",
      "          1.5963e+00,  2.2540e+00, -4.2515e-02,  1.8053e+00,  2.4142e+00],\n",
      "        [ 2.6758e+00, -2.7461e-01,  1.8192e+00,  1.7154e+00,  1.6067e+00,\n",
      "          1.1576e+00,  1.9075e-01,  1.3011e+00,  8.7750e-01, -4.7105e-01,\n",
      "          1.6394e+00,  5.9529e-01,  1.5266e+00,  2.2674e+00,  2.2181e+00,\n",
      "          2.0896e+00,  1.9075e+00,  2.1356e+00,  2.0848e+00,  1.8438e+00,\n",
      "          1.9599e+00,  1.9913e+00, -4.5125e-01,  1.6720e+00,  2.4523e+00],\n",
      "        [ 2.7297e+00, -2.3661e-01,  2.3413e+00,  2.2120e+00,  1.3475e+00,\n",
      "          6.1116e-01,  3.3524e-01,  1.4278e+00,  2.8766e-01, -6.5802e-01,\n",
      "          1.7320e+00,  4.4363e-01,  1.6955e+00,  2.0797e+00,  2.3386e+00,\n",
      "          2.2835e+00,  1.9259e+00,  3.0673e+00,  1.7308e+00,  1.4359e+00,\n",
      "          1.5040e+00,  2.3854e+00,  3.9313e-02,  1.5461e+00,  2.1870e+00],\n",
      "        [ 2.7106e+00,  7.5171e-02,  1.8430e+00,  1.8584e+00,  1.5229e+00,\n",
      "          1.0561e+00,  4.3339e-01,  1.4839e+00, -2.5110e-01, -5.7676e-01,\n",
      "          1.7851e+00,  4.4541e-01,  1.7354e+00,  1.7959e+00,  1.5949e+00,\n",
      "          2.0366e+00,  1.6478e+00,  2.7550e+00,  1.6989e+00,  1.6158e+00,\n",
      "          1.0543e+00,  2.0451e+00, -5.0420e-02,  1.5473e+00,  2.1231e+00],\n",
      "        [ 2.6646e+00, -2.7594e-01,  2.3774e+00,  2.0302e+00,  1.6153e+00,\n",
      "          1.2004e+00,  1.9783e-01,  1.5477e+00,  5.9243e-01, -8.1769e-01,\n",
      "          1.8722e+00,  1.0680e-02,  1.4928e+00,  1.7908e+00,  2.2694e+00,\n",
      "          2.2509e+00,  2.2761e+00,  2.3203e+00,  2.2116e+00,  1.6914e+00,\n",
      "          1.4122e+00,  1.9214e+00,  1.0271e-01,  1.1924e+00,  2.2510e+00],\n",
      "        [ 3.0378e+00, -1.6746e-01,  2.4174e+00,  1.5109e+00,  9.5959e-01,\n",
      "          4.5146e-01,  3.2845e-01,  1.4143e+00,  1.2455e-01, -6.6448e-01,\n",
      "          1.6044e+00,  1.1349e+00,  1.1672e+00,  1.6381e+00,  2.3263e+00,\n",
      "          2.0823e+00,  2.5268e+00,  2.5273e+00,  1.7026e+00,  1.8465e+00,\n",
      "          1.2440e+00,  1.8389e+00, -2.8909e-01,  1.4553e+00,  2.1821e+00],\n",
      "        [ 2.7441e+00, -2.0928e-01,  1.9870e+00,  1.6959e+00,  1.1945e+00,\n",
      "          2.1830e-01,  1.1922e-01,  1.2443e+00,  4.5050e-01, -9.1474e-01,\n",
      "          1.6108e+00,  2.9855e-01,  1.4787e+00,  1.7406e+00,  2.4576e+00,\n",
      "          2.0652e+00,  2.0181e+00,  2.2380e+00,  1.6991e+00,  1.4303e+00,\n",
      "          1.6285e+00,  1.9142e+00, -1.1443e-01,  1.5242e+00,  2.3237e+00],\n",
      "        [ 2.7045e+00, -2.5382e-01,  2.1003e+00,  1.7981e+00,  1.2768e+00,\n",
      "          8.3791e-01,  4.6578e-01,  1.4828e+00,  5.4983e-01, -4.7775e-01,\n",
      "          1.9482e+00,  4.2374e-01,  1.9673e+00,  1.9958e+00,  2.2123e+00,\n",
      "          2.2159e+00,  2.1589e+00,  3.1373e+00,  1.6538e+00,  1.4248e+00,\n",
      "          1.4382e+00,  2.4045e+00, -6.1559e-02,  1.2612e+00,  2.3144e+00],\n",
      "        [ 2.6132e+00, -5.1782e-02,  2.0152e+00,  1.3965e+00,  1.5509e+00,\n",
      "          1.4342e+00,  4.5245e-01,  1.2608e+00,  7.0406e-01, -8.3103e-01,\n",
      "          1.9495e+00,  4.3826e-01,  1.8297e+00,  1.6559e+00,  2.1577e+00,\n",
      "          2.4767e+00,  2.2381e+00,  3.1668e+00,  1.9491e+00,  2.3580e+00,\n",
      "          1.6138e+00,  2.2957e+00,  2.7269e-03,  1.3558e+00,  2.1389e+00],\n",
      "        [ 2.7894e+00, -5.1447e-01,  1.9510e+00,  1.6936e+00,  1.0302e+00,\n",
      "          8.2411e-01,  3.7674e-01,  1.1233e+00,  7.2381e-01, -5.0653e-01,\n",
      "          1.8015e+00,  7.2203e-01,  1.4770e+00,  1.4904e+00,  2.5399e+00,\n",
      "          2.1184e+00,  1.7560e+00,  3.0082e+00,  1.7189e+00,  1.6145e+00,\n",
      "          1.1711e+00,  2.1334e+00,  2.6941e-01,  1.8013e+00,  2.5830e+00],\n",
      "        [ 3.0258e+00, -3.3288e-01,  1.5970e+00,  2.0559e+00,  1.3157e+00,\n",
      "          1.2086e+00,  3.5168e-01,  1.6028e+00,  6.0160e-01, -3.6271e-01,\n",
      "          1.6005e+00,  8.8634e-01,  1.5353e+00,  2.2071e+00,  2.7716e+00,\n",
      "          2.2606e+00,  2.3606e+00,  2.7899e+00,  1.8330e+00,  2.2299e+00,\n",
      "          1.5001e+00,  1.8291e+00,  4.2770e-02,  1.7021e+00,  2.0026e+00],\n",
      "        [ 2.9456e+00, -4.9136e-01,  2.1581e+00,  1.9291e+00,  4.1957e-01,\n",
      "          7.2703e-01,  4.1952e-01,  1.1124e+00,  7.6827e-01, -3.3147e-01,\n",
      "          2.1433e+00,  8.7839e-01,  1.6184e+00,  2.0780e+00,  1.9108e+00,\n",
      "          2.1546e+00,  2.5319e+00,  2.8570e+00,  1.8277e+00,  1.6199e+00,\n",
      "          1.5135e+00,  1.8986e+00, -1.6364e-01,  1.4924e+00,  2.5278e+00],\n",
      "        [ 3.2187e+00, -4.0083e-01,  1.8985e+00,  1.6711e+00,  6.5011e-01,\n",
      "          9.1891e-01,  1.6680e-01,  1.2797e+00,  4.2975e-01, -7.1115e-01,\n",
      "          1.4590e+00,  8.6436e-01,  1.6160e+00,  1.7855e+00,  2.4256e+00,\n",
      "          2.3866e+00,  2.5598e+00,  2.3262e+00,  1.8174e+00,  1.7452e+00,\n",
      "          1.2046e+00,  1.8088e+00, -1.9858e-01,  1.2723e+00,  2.6109e+00],\n",
      "        [ 2.9028e+00, -2.1838e-01,  2.2758e+00,  1.4516e+00,  1.3145e+00,\n",
      "          1.3131e+00, -1.0714e-02,  1.2626e+00,  5.5106e-01, -8.1575e-01,\n",
      "          1.8291e+00,  6.3001e-01,  1.5514e+00,  2.2427e+00,  2.3965e+00,\n",
      "          1.9236e+00,  2.1346e+00,  2.6603e+00,  1.7233e+00,  1.1377e+00,\n",
      "          1.4825e+00,  1.9616e+00,  2.8153e-01,  1.5998e+00,  1.9294e+00],\n",
      "        [ 2.1721e+00,  2.4170e-02,  1.3459e+00,  1.6926e+00,  1.6480e+00,\n",
      "          1.4667e+00,  5.4940e-01,  1.1799e+00,  4.1013e-01, -5.5320e-01,\n",
      "          1.4189e+00,  7.8073e-01,  1.2464e+00,  1.8185e+00,  2.4790e+00,\n",
      "          2.2746e+00,  1.8603e+00,  2.8747e+00,  1.7022e+00,  2.0616e+00,\n",
      "          1.3084e+00,  2.2368e+00,  8.6901e-02,  1.7352e+00,  1.9371e+00],\n",
      "        [ 2.9467e+00, -4.2073e-01,  2.1396e+00,  1.5929e+00,  9.3180e-01,\n",
      "          9.5441e-01, -1.8679e-01,  1.3592e+00,  1.1028e+00, -9.2671e-01,\n",
      "          2.1413e+00,  1.0845e+00,  1.5550e+00,  1.7273e+00,  2.4528e+00,\n",
      "          1.8192e+00,  1.8869e+00,  2.7255e+00,  1.8924e+00,  1.5779e+00,\n",
      "          1.4620e+00,  2.1023e+00, -8.6434e-02,  1.4509e+00,  2.3144e+00],\n",
      "        [ 2.5985e+00, -2.1768e-01,  1.7382e+00,  1.8180e+00,  1.3653e+00,\n",
      "          1.0493e+00,  5.8730e-01,  1.3578e+00,  7.2879e-01, -5.9607e-01,\n",
      "          1.8573e+00,  5.1904e-01,  1.7816e+00,  1.7183e+00,  2.4104e+00,\n",
      "          1.9990e+00,  2.4600e+00,  2.5723e+00,  1.7349e+00,  1.5132e+00,\n",
      "          1.8192e+00,  1.7119e+00, -2.3874e-01,  1.2927e+00,  2.4141e+00],\n",
      "        [ 2.7022e+00, -2.1029e-01,  2.0557e+00,  1.4603e+00,  9.4934e-01,\n",
      "          8.9775e-01,  1.3769e-01,  1.9043e+00,  5.5504e-01, -8.2422e-01,\n",
      "          2.2330e+00,  7.9926e-01,  1.1132e+00,  2.2589e+00,  2.5325e+00,\n",
      "          1.9229e+00,  1.9569e+00,  2.6900e+00,  2.0014e+00,  1.3127e+00,\n",
      "          1.4231e+00,  2.1043e+00, -1.6252e-01,  1.3141e+00,  2.1272e+00],\n",
      "        [ 2.7380e+00, -3.2466e-01,  2.3424e+00,  1.5405e+00,  1.4442e+00,\n",
      "          1.0840e+00,  4.3210e-01,  1.4152e+00,  7.7913e-01, -1.0610e+00,\n",
      "          1.7053e+00,  7.7625e-01,  1.6722e+00,  1.4550e+00,  2.0542e+00,\n",
      "          2.5777e+00,  2.1822e+00,  2.8343e+00,  1.9637e+00,  2.1380e+00,\n",
      "          1.5901e+00,  2.1147e+00,  4.2798e-03,  1.8818e+00,  2.2349e+00],\n",
      "        [ 2.9667e+00, -5.5841e-01,  2.0506e+00,  1.5702e+00,  1.4128e+00,\n",
      "          9.8082e-01,  5.7003e-01,  6.6381e-01,  2.5851e-01, -7.0832e-01,\n",
      "          1.5917e+00,  8.8637e-01,  1.8853e+00,  1.9218e+00,  2.0381e+00,\n",
      "          2.5731e+00,  2.5292e+00,  2.8834e+00,  1.7640e+00,  1.6017e+00,\n",
      "          1.8361e+00,  2.2322e+00, -2.7986e-01,  1.2873e+00,  2.4222e+00],\n",
      "        [ 2.9195e+00,  1.6072e-01,  2.2539e+00,  1.8960e+00,  1.3712e+00,\n",
      "          1.3246e+00,  3.8025e-01,  1.1362e+00,  6.1206e-01, -6.2877e-01,\n",
      "          1.7364e+00,  3.7938e-01,  1.4635e+00,  2.2212e+00,  2.4412e+00,\n",
      "          2.5769e+00,  1.8494e+00,  2.8701e+00,  2.0673e+00,  1.9437e+00,\n",
      "          1.4068e+00,  1.9185e+00, -2.3271e-01,  1.4848e+00,  2.1711e+00],\n",
      "        [ 2.6902e+00, -4.5245e-01,  1.7977e+00,  1.5167e+00,  1.4082e+00,\n",
      "          9.3842e-01,  2.6257e-01,  1.7696e+00,  5.6477e-01, -4.7828e-01,\n",
      "          1.8364e+00,  7.7163e-01,  1.0505e+00,  1.9020e+00,  2.2976e+00,\n",
      "          2.4147e+00,  2.4279e+00,  2.3054e+00,  2.1482e+00,  1.4713e+00,\n",
      "          1.6904e+00,  2.1897e+00, -1.1652e-01,  1.1790e+00,  1.9787e+00],\n",
      "        [ 2.6500e+00, -1.0929e-01,  2.1276e+00,  1.8794e+00,  9.9871e-01,\n",
      "          1.1244e+00,  3.4762e-01,  1.2345e+00,  4.3330e-01, -7.7278e-01,\n",
      "          1.9924e+00,  3.7977e-01,  1.1268e+00,  1.5299e+00,  2.3711e+00,\n",
      "          2.2423e+00,  2.3516e+00,  3.2314e+00,  1.7044e+00,  1.7643e+00,\n",
      "          1.6890e+00,  2.3394e+00, -1.2662e-01,  1.7027e+00,  2.7953e+00],\n",
      "        [ 2.7276e+00, -3.7011e-01,  2.0661e+00,  1.4293e+00,  7.7530e-01,\n",
      "          4.0324e-01,  5.1543e-02,  6.4787e-01,  2.8005e-01, -8.5908e-01,\n",
      "          1.9511e+00,  1.0215e+00,  1.4699e+00,  1.5186e+00,  2.3781e+00,\n",
      "          2.3886e+00,  2.6711e+00,  3.0414e+00,  1.7369e+00,  1.5585e+00,\n",
      "          1.2825e+00,  2.1785e+00, -9.7443e-02,  1.4014e+00,  2.2524e+00],\n",
      "        [ 2.9637e+00,  9.8199e-02,  1.7672e+00,  1.7640e+00,  1.0507e+00,\n",
      "          1.0224e+00,  5.2928e-01,  1.3824e+00,  7.3018e-01, -5.6416e-01,\n",
      "          1.9050e+00,  1.3230e+00,  1.7622e+00,  1.7938e+00,  2.3559e+00,\n",
      "          2.5495e+00,  2.1988e+00,  2.5539e+00,  1.2494e+00,  1.9532e+00,\n",
      "          1.4935e+00,  2.2209e+00, -1.9073e-01,  1.9225e+00,  2.5733e+00],\n",
      "        [ 2.9322e+00, -2.1229e-01,  1.9694e+00,  1.5730e+00,  1.3275e+00,\n",
      "          8.0035e-01,  2.3802e-01,  1.6392e+00,  6.3400e-01, -4.3686e-01,\n",
      "          1.6824e+00,  5.3086e-01,  1.4958e+00,  1.8208e+00,  2.4159e+00,\n",
      "          2.0173e+00,  2.1382e+00,  2.6632e+00,  2.1281e+00,  1.8170e+00,\n",
      "          1.0963e+00,  1.9316e+00, -9.7795e-02,  1.4081e+00,  2.5155e+00],\n",
      "        [ 3.2130e+00, -2.8119e-01,  2.0351e+00,  1.6256e+00,  5.4622e-01,\n",
      "          1.1481e+00, -5.7560e-03,  1.1743e+00,  7.2385e-01, -6.0440e-01,\n",
      "          1.6582e+00,  9.8945e-01,  1.4562e+00,  1.3585e+00,  2.3925e+00,\n",
      "          2.4155e+00,  1.7705e+00,  2.7099e+00,  1.8551e+00,  1.5297e+00,\n",
      "          1.5741e+00,  1.7587e+00,  1.6322e-02,  1.5930e+00,  2.1363e+00],\n",
      "        [ 2.6569e+00, -9.8376e-02,  2.4077e+00,  1.9549e+00,  1.1091e+00,\n",
      "          4.7822e-01,  4.0636e-01,  1.2337e+00,  8.1128e-01, -4.1550e-01,\n",
      "          1.8918e+00,  5.5825e-01,  1.7018e+00,  1.6707e+00,  2.4294e+00,\n",
      "          2.1607e+00,  2.5118e+00,  2.8731e+00,  2.1244e+00,  1.7845e+00,\n",
      "          1.3186e+00,  1.6688e+00, -2.5585e-01,  1.2979e+00,  2.3577e+00],\n",
      "        [ 2.7805e+00, -7.3552e-02,  1.7280e+00,  1.7127e+00,  1.2278e+00,\n",
      "          1.0301e+00,  2.4726e-01,  1.6916e+00,  9.3004e-01, -4.9780e-01,\n",
      "          1.9164e+00,  1.0865e+00,  1.4786e+00,  1.8699e+00,  2.3097e+00,\n",
      "          2.3830e+00,  2.2409e+00,  2.5008e+00,  2.0086e+00,  1.7884e+00,\n",
      "          1.2779e+00,  2.0642e+00,  6.3278e-02,  2.1911e+00,  2.4306e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.8493, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3148, -0.0415,  1.5516,  2.0701,  1.2221,  0.8133,  0.2703,  1.1296,\n",
      "          1.3020, -1.1141,  2.2546,  1.4883,  1.6665,  1.7292,  1.4237,  1.6717,\n",
      "          1.6083,  2.1186,  2.3090,  1.8256,  1.9384,  2.1466, -0.3400,  1.6715,\n",
      "          2.0358],\n",
      "        [ 2.8345, -0.3681,  1.5264,  2.0630,  0.9179,  1.3608,  0.4092,  1.3128,\n",
      "          0.8403, -0.3678,  1.7843,  1.7899,  1.2805,  1.4716,  2.2431,  1.7286,\n",
      "          1.8599,  2.0581,  1.8275,  2.3639,  1.8006,  2.4218, -0.0647,  1.6851,\n",
      "          2.1682],\n",
      "        [ 3.0516, -0.4287,  1.4193,  1.9178,  1.1268,  1.2549,  0.3984,  0.8589,\n",
      "          0.7458, -0.9942,  2.2462,  1.1981,  1.9398,  1.7370,  1.4244,  1.7360,\n",
      "          1.8481,  2.5679,  2.4235,  1.4625,  2.0328,  2.0446, -0.3249,  0.8896,\n",
      "          2.0487],\n",
      "        [ 3.0968, -0.1585,  1.3943,  1.9532,  1.6364,  1.2206,  0.2818,  1.2683,\n",
      "          1.2148, -0.8836,  1.8523,  1.6311,  1.3011,  2.0274,  1.7001,  1.5501,\n",
      "          1.6436,  1.9846,  2.4468,  1.8078,  1.6298,  2.2452, -0.0714,  1.1770,\n",
      "          2.2505],\n",
      "        [ 3.2167, -0.6092,  1.4805,  1.9352,  1.3581,  1.2036, -0.1530,  1.5037,\n",
      "          1.1076, -0.9238,  2.1690,  1.2042,  1.5404,  1.9866,  1.6732,  1.7704,\n",
      "          1.5352,  2.0733,  2.1842,  1.6473,  1.7159,  1.9240, -0.0848,  1.2484,\n",
      "          2.6742],\n",
      "        [ 3.1061, -0.7751,  1.3501,  2.1058,  1.2809,  1.4530,  0.3028,  0.9814,\n",
      "          0.6906, -0.9295,  2.3071,  1.3723,  1.3170,  2.1550,  1.6082,  1.5556,\n",
      "          1.8835,  1.9645,  2.2221,  1.7330,  1.6155,  2.1614,  0.0988,  1.2509,\n",
      "          2.1639],\n",
      "        [ 3.3044, -0.2468,  1.1120,  2.1251,  1.3623,  1.0179,  0.6852,  1.0653,\n",
      "          1.2256, -0.7458,  2.1626,  2.0617,  1.7141,  1.9677,  1.4524,  1.7250,\n",
      "          1.0827,  2.4215,  1.7960,  1.6366,  1.7077,  1.9302,  0.1974,  1.8027,\n",
      "          1.7668],\n",
      "        [ 2.9126, -0.1303,  1.0719,  2.0458,  1.3991,  1.4337,  0.5038,  1.1036,\n",
      "          0.9567, -1.2255,  2.2355,  1.7340,  1.2335,  1.8212,  2.0065,  1.6336,\n",
      "          1.8690,  2.5054,  2.0710,  1.7061,  1.7491,  2.1627,  0.2207,  1.7104,\n",
      "          1.9407],\n",
      "        [ 2.9782,  0.0726,  1.3337,  2.2123,  1.0717,  1.3169,  0.0138,  1.8283,\n",
      "          1.0322, -0.8124,  2.0621,  1.3032,  1.2370,  1.9168,  2.0228,  1.5645,\n",
      "          1.7956,  2.4154,  2.0670,  1.8049,  1.6537,  2.1136, -0.5345,  1.7076,\n",
      "          1.8770],\n",
      "        [ 3.1906, -0.0793,  1.5734,  1.4157,  0.8124,  1.7509,  0.1082,  1.8291,\n",
      "          1.4361, -0.1062,  2.1019,  1.6332,  1.0913,  1.6675,  2.1053,  1.4935,\n",
      "          1.4546,  2.3419,  1.9468,  2.1407,  2.1154,  2.1405, -0.2281,  1.5828,\n",
      "          2.1004],\n",
      "        [ 3.2120, -0.2604,  1.0311,  2.2709,  1.5678,  0.9183,  0.6276,  1.5095,\n",
      "          1.4300, -0.5692,  2.1180,  2.1848,  1.5463,  1.6793,  1.6735,  1.7073,\n",
      "          0.9775,  1.9422,  1.9126,  2.3261,  1.6608,  2.4735,  0.5213,  1.8190,\n",
      "          2.0293],\n",
      "        [ 3.2861,  0.3147,  1.1799,  2.1642,  1.0338,  1.4061,  0.2575,  0.9362,\n",
      "          1.2982, -0.5997,  2.1465,  1.6003,  1.5256,  1.0960,  1.9734,  1.5196,\n",
      "          1.6207,  2.3392,  1.4418,  2.3398,  2.2407,  2.1569,  0.4116,  2.0921,\n",
      "          2.1914],\n",
      "        [ 3.2791,  0.1324,  1.4324,  1.8279,  0.4931,  1.6620, -0.3407,  1.2831,\n",
      "          1.2524, -0.6900,  1.8944,  2.2614,  1.4262,  1.5974,  1.7942,  2.1224,\n",
      "          1.5668,  3.1418,  1.6940,  2.6207,  1.8026,  1.8302, -0.3608,  1.4525,\n",
      "          2.0406],\n",
      "        [ 3.2450, -0.4573,  1.5783,  1.2198,  0.6595,  1.2159, -0.1944,  1.3556,\n",
      "          1.3326, -0.8843,  2.3287,  1.3386,  1.4088,  1.8778,  1.7018,  1.6693,\n",
      "          2.0368,  1.6097,  2.4739,  2.1425,  2.0913,  1.8062, -0.2371,  0.7698,\n",
      "          2.2507]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Epoch:2, Average Training Loss=3.6406582832336425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [03:03<03:03, 91.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Average Validation Accuracy=0.03225806451612903\n",
      "TRAIN OUTPUTS SequenceClassifierOutput(loss=tensor(3.5930, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.5382e+00, -9.7190e-02,  1.3465e+00,  2.1940e+00,  1.3989e+00,\n",
      "          1.2843e+00,  2.6810e-02,  1.7602e+00,  1.4582e+00, -2.5856e-01,\n",
      "          2.3361e+00,  2.3336e+00,  1.7071e+00,  2.1175e+00,  9.2229e-01,\n",
      "          1.4614e+00,  2.3063e-01,  1.2324e+00,  2.8012e+00,  1.4679e+00,\n",
      "          1.7493e+00,  2.6379e+00,  4.0192e-01,  1.2529e+00,  2.9788e+00],\n",
      "        [ 2.3859e+00,  3.5206e-01,  8.9234e-01,  2.0308e+00,  1.6268e+00,\n",
      "          1.5164e+00, -1.4497e-02,  1.5207e+00,  1.3783e+00, -3.2745e-01,\n",
      "          2.1549e+00,  2.6495e+00,  1.9673e+00,  2.0031e+00,  9.5775e-01,\n",
      "          1.3155e+00,  7.9037e-01,  1.4023e+00,  2.3866e+00,  2.2971e+00,\n",
      "          2.2030e+00,  2.1375e+00, -1.4979e-01,  1.3146e+00,  2.7027e+00],\n",
      "        [ 2.9753e+00,  3.7799e-01,  8.6153e-01,  2.0457e+00,  1.7137e+00,\n",
      "          1.4367e+00,  4.5802e-01,  1.5983e+00,  1.5931e+00, -9.8332e-02,\n",
      "          1.7839e+00,  2.8306e+00,  1.6030e+00,  1.9171e+00,  1.2359e+00,\n",
      "          1.3680e+00,  1.0673e+00,  9.7689e-01,  2.8705e+00,  2.2593e+00,\n",
      "          1.6977e+00,  2.4702e+00,  1.4545e-01,  1.3124e+00,  2.8865e+00],\n",
      "        [ 2.5321e+00,  8.4977e-01,  1.2809e+00,  2.0159e+00,  8.8751e-01,\n",
      "          1.6335e+00, -1.1030e-01,  1.6604e+00,  1.4782e+00, -1.3454e-01,\n",
      "          2.3189e+00,  2.0281e+00,  1.5931e+00,  2.0380e+00,  1.2517e+00,\n",
      "          1.3110e+00,  1.1627e+00,  1.6023e+00,  2.9955e+00,  1.8352e+00,\n",
      "          1.8462e+00,  2.2760e+00,  8.9594e-02,  1.0697e+00,  2.8978e+00],\n",
      "        [ 2.8194e+00,  1.2755e-01,  8.1885e-01,  1.9263e+00,  1.1234e+00,\n",
      "          1.4578e+00,  2.0815e-01,  1.6473e+00,  1.6207e+00,  2.0749e-01,\n",
      "          2.2438e+00,  2.2935e+00,  1.2758e+00,  2.2015e+00,  8.5475e-01,\n",
      "          1.2710e+00,  8.0305e-01,  1.3087e+00,  2.3477e+00,  1.7657e+00,\n",
      "          2.1077e+00,  2.2737e+00,  3.4793e-01,  1.3089e+00,  2.3666e+00],\n",
      "        [ 2.6284e+00,  7.1404e-01,  9.4564e-01,  2.2949e+00,  1.4214e+00,\n",
      "          1.8884e+00,  2.9009e-01,  1.5353e+00,  1.2942e+00,  6.0782e-02,\n",
      "          2.0117e+00,  2.3465e+00,  1.5054e+00,  2.2322e+00,  1.5314e+00,\n",
      "          1.2272e+00,  1.1326e+00,  1.4820e+00,  2.9015e+00,  1.9677e+00,\n",
      "          1.5095e+00,  2.6088e+00, -1.4372e-01,  1.3096e+00,  2.4811e+00],\n",
      "        [ 2.5411e+00,  2.3500e-01,  6.4435e-01,  2.3980e+00,  1.2064e+00,\n",
      "          1.1523e+00,  7.9844e-01,  1.3361e+00,  1.6363e+00, -1.8619e-02,\n",
      "          2.2879e+00,  2.6921e+00,  1.8793e+00,  1.9390e+00,  7.1396e-01,\n",
      "          1.7668e+00,  5.1537e-01,  1.4801e+00,  2.1341e+00,  2.0116e+00,\n",
      "          1.7239e+00,  1.9806e+00,  3.7108e-01,  1.3827e+00,  2.8172e+00],\n",
      "        [ 2.4599e+00,  4.2868e-01,  8.5278e-01,  2.4320e+00,  1.2165e+00,\n",
      "          1.5479e+00, -7.2479e-03,  1.6846e+00,  1.6705e+00, -8.9357e-03,\n",
      "          2.0472e+00,  2.2651e+00,  1.2737e+00,  1.6115e+00,  1.1723e+00,\n",
      "          1.3439e+00,  7.0723e-01,  1.2616e+00,  2.5605e+00,  1.9293e+00,\n",
      "          1.8891e+00,  2.3017e+00,  3.7830e-02,  1.3645e+00,  3.0131e+00],\n",
      "        [ 3.0445e+00,  2.8085e-01,  1.2774e+00,  2.2202e+00,  1.2801e+00,\n",
      "          1.5597e+00,  2.6309e-03,  1.9499e+00,  1.6075e+00, -9.4585e-02,\n",
      "          2.3088e+00,  2.4878e+00,  1.6750e+00,  2.4359e+00,  1.2741e+00,\n",
      "          1.1768e+00,  9.8275e-01,  1.1533e+00,  3.1239e+00,  1.6028e+00,\n",
      "          1.9007e+00,  2.7718e+00, -7.9116e-02,  1.0008e+00,  2.4714e+00],\n",
      "        [ 2.9189e+00,  4.1792e-02,  8.6627e-01,  2.2722e+00,  1.2097e+00,\n",
      "          1.5818e+00,  8.2529e-02,  1.4799e+00,  1.4337e+00,  2.0969e-01,\n",
      "          2.2204e+00,  2.4012e+00,  1.7105e+00,  1.7190e+00,  1.1045e+00,\n",
      "          1.2085e+00,  1.2661e+00,  1.4668e+00,  2.8635e+00,  1.9352e+00,\n",
      "          1.6773e+00,  2.3514e+00, -1.0607e-01,  1.5142e+00,  2.7298e+00],\n",
      "        [ 2.7873e+00,  2.8960e-01,  7.0930e-01,  1.6317e+00,  1.0393e+00,\n",
      "          1.2669e+00,  1.5193e-01,  1.8246e+00,  1.7199e+00, -1.4909e-01,\n",
      "          2.5593e+00,  2.1766e+00,  1.3697e+00,  1.9434e+00,  7.2779e-01,\n",
      "          1.1853e+00,  1.0849e+00,  1.1212e+00,  2.8205e+00,  1.6061e+00,\n",
      "          1.6450e+00,  2.3249e+00,  4.0383e-01,  7.7234e-01,  2.6728e+00],\n",
      "        [ 3.0512e+00, -9.3345e-02,  8.1909e-01,  1.9098e+00,  6.8807e-01,\n",
      "          8.9440e-01, -1.0046e-01,  1.4562e+00,  1.2332e+00, -3.0511e-01,\n",
      "          2.4727e+00,  2.5257e+00,  1.4325e+00,  1.8325e+00,  1.0444e+00,\n",
      "          8.6692e-01,  3.4708e-01,  1.7050e+00,  2.5367e+00,  1.8630e+00,\n",
      "          1.8847e+00,  2.4648e+00,  1.8161e-01,  1.4421e+00,  2.6755e+00],\n",
      "        [ 2.8372e+00,  9.2412e-02,  8.9999e-01,  2.2478e+00,  1.4360e+00,\n",
      "          1.1515e+00,  1.4187e-01,  1.4936e+00,  1.2755e+00, -2.6162e-01,\n",
      "          2.3976e+00,  2.1013e+00,  1.4131e+00,  2.4216e+00,  1.2498e+00,\n",
      "          1.2980e+00,  1.0698e+00,  7.4709e-01,  2.8117e+00,  2.2404e+00,\n",
      "          1.8518e+00,  1.9684e+00,  7.8385e-02,  1.4085e+00,  2.3257e+00],\n",
      "        [ 2.7285e+00,  5.1177e-01,  4.4010e-01,  2.6773e+00,  1.1783e+00,\n",
      "          1.1387e+00,  1.2920e-01,  1.7675e+00,  1.7249e+00, -1.2640e-01,\n",
      "          2.4741e+00,  2.0481e+00,  1.5450e+00,  1.8363e+00,  9.1279e-01,\n",
      "          1.4041e+00,  6.6383e-01,  7.8332e-01,  2.6106e+00,  2.2471e+00,\n",
      "          1.8986e+00,  2.1120e+00,  4.3127e-01,  1.3337e+00,  2.9742e+00],\n",
      "        [ 2.9196e+00,  8.1569e-02,  1.1360e+00,  2.3074e+00,  1.4772e+00,\n",
      "          1.4413e+00,  6.4925e-02,  1.6948e+00,  1.6185e+00,  3.5736e-01,\n",
      "          2.0881e+00,  2.1465e+00,  1.7694e+00,  1.9730e+00,  1.0227e+00,\n",
      "          1.5507e+00,  7.4598e-01,  1.1138e+00,  3.0413e+00,  2.1527e+00,\n",
      "          1.7857e+00,  2.1431e+00, -2.9798e-01,  1.2646e+00,  2.7930e+00],\n",
      "        [ 3.0602e+00, -2.8846e-02,  1.0211e+00,  2.1338e+00,  8.8325e-01,\n",
      "          1.6107e+00, -4.3063e-01,  1.5759e+00,  1.8601e+00, -2.8482e-01,\n",
      "          2.9213e+00,  2.1681e+00,  1.4165e+00,  1.7551e+00,  1.2601e+00,\n",
      "          1.2073e+00,  8.5432e-01,  1.2623e+00,  3.0228e+00,  2.0042e+00,\n",
      "          2.0255e+00,  2.2473e+00, -4.1185e-01,  1.2480e+00,  3.0705e+00],\n",
      "        [ 3.1295e+00,  1.9206e-01,  1.4457e+00,  1.9488e+00,  1.2679e+00,\n",
      "          1.2867e+00, -7.2793e-02,  1.4331e+00,  1.1238e+00, -1.6716e-01,\n",
      "          2.4589e+00,  2.4677e+00,  1.5952e+00,  1.7838e+00,  1.2633e+00,\n",
      "          1.2934e+00,  1.2104e+00,  1.3693e+00,  3.0895e+00,  1.7149e+00,\n",
      "          1.4017e+00,  2.2777e+00,  1.0362e-02,  1.0837e+00,  2.5896e+00],\n",
      "        [ 2.8242e+00,  4.0629e-01,  7.4657e-01,  2.2709e+00,  1.7563e+00,\n",
      "          1.1612e+00,  3.3981e-01,  1.9090e+00,  1.6301e+00,  8.3243e-02,\n",
      "          1.9263e+00,  2.7135e+00,  1.4823e+00,  1.8788e+00,  1.3859e+00,\n",
      "          1.5158e+00,  3.2633e-01,  4.8060e-01,  3.0128e+00,  2.3509e+00,\n",
      "          1.6357e+00,  2.2495e+00,  1.9337e-01,  1.2314e+00,  2.5878e+00],\n",
      "        [ 3.1426e+00, -1.0792e-01,  1.0173e+00,  2.5777e+00,  1.4581e+00,\n",
      "          1.2068e+00,  5.0708e-01,  1.2485e+00,  1.6130e+00, -4.5214e-02,\n",
      "          2.5432e+00,  2.3097e+00,  1.4472e+00,  1.8395e+00,  8.8615e-01,\n",
      "          1.1148e+00,  7.1899e-01,  1.5328e+00,  2.6656e+00,  2.1774e+00,\n",
      "          1.5476e+00,  2.4336e+00, -3.6011e-01,  1.1839e+00,  2.7308e+00],\n",
      "        [ 2.5168e+00,  4.2891e-01,  1.4714e+00,  2.2525e+00,  1.3654e+00,\n",
      "          1.4643e+00,  1.9373e-01,  1.6360e+00,  1.6151e+00, -1.4239e-01,\n",
      "          1.6570e+00,  1.9601e+00,  1.5927e+00,  2.2863e+00,  9.8751e-01,\n",
      "          1.5355e+00,  9.9680e-01,  1.0348e+00,  3.1218e+00,  1.8392e+00,\n",
      "          1.7861e+00,  1.9248e+00,  2.8169e-01,  8.2282e-01,  2.5979e+00],\n",
      "        [ 2.5760e+00,  4.5947e-01,  1.1744e+00,  2.0112e+00,  1.2523e+00,\n",
      "          1.2453e+00, -6.0094e-02,  1.0991e+00,  1.4527e+00,  3.8329e-02,\n",
      "          2.4456e+00,  2.1486e+00,  1.6597e+00,  2.1337e+00,  8.9321e-01,\n",
      "          1.2441e+00,  1.5086e+00,  1.2226e+00,  3.4893e+00,  1.8011e+00,\n",
      "          1.4998e+00,  2.1502e+00, -3.0273e-01,  1.2425e+00,  2.5813e+00],\n",
      "        [ 2.9016e+00,  3.0504e-01,  1.0224e+00,  1.7000e+00,  1.0245e+00,\n",
      "          1.2191e+00, -2.6599e-01,  1.4463e+00,  1.5109e+00, -1.6742e-01,\n",
      "          2.4789e+00,  2.0683e+00,  1.5899e+00,  2.0904e+00,  1.0549e+00,\n",
      "          1.2079e+00,  1.0122e+00,  9.6132e-01,  2.4981e+00,  1.8745e+00,\n",
      "          1.3700e+00,  1.9895e+00, -1.5544e-01,  1.1880e+00,  2.6218e+00],\n",
      "        [ 2.3406e+00,  2.6138e-01,  6.7400e-01,  2.8798e+00,  1.4590e+00,\n",
      "          1.3782e+00,  4.0526e-01,  1.8494e+00,  1.3789e+00, -4.1181e-01,\n",
      "          2.3795e+00,  2.3397e+00,  1.5485e+00,  2.0252e+00,  1.1733e+00,\n",
      "          1.2996e+00,  5.8815e-01,  1.2049e+00,  3.1122e+00,  2.0891e+00,\n",
      "          1.6156e+00,  2.4701e+00, -1.8880e-01,  1.0404e+00,  2.5155e+00],\n",
      "        [ 3.0031e+00,  1.3353e-01,  1.2927e+00,  2.5979e+00,  1.4374e+00,\n",
      "          1.3568e+00,  3.5987e-01,  1.5459e+00,  8.8614e-01, -6.4918e-01,\n",
      "          2.2287e+00,  2.3688e+00,  1.7681e+00,  1.9188e+00,  1.1792e+00,\n",
      "          1.3252e+00,  7.1720e-01,  1.3071e+00,  3.2169e+00,  1.6207e+00,\n",
      "          1.5835e+00,  2.1580e+00,  1.1897e-01,  1.0847e+00,  2.9270e+00],\n",
      "        [ 2.5859e+00,  1.4990e-01,  1.1735e+00,  2.2011e+00,  1.6318e+00,\n",
      "          1.3876e+00,  5.6383e-02,  2.1658e+00,  1.3883e+00,  2.3379e-01,\n",
      "          2.2547e+00,  2.4048e+00,  1.4684e+00,  1.8786e+00,  1.0283e+00,\n",
      "          1.4863e+00,  7.9834e-01,  1.0891e+00,  3.2690e+00,  1.5058e+00,\n",
      "          1.9302e+00,  2.8315e+00,  1.1861e-01,  9.5355e-01,  3.0813e+00],\n",
      "        [ 2.7835e+00,  1.3393e-01,  5.7237e-01,  2.1318e+00,  1.3922e+00,\n",
      "          9.6331e-01,  1.4984e-01,  1.3152e+00,  1.5100e+00,  2.3139e-01,\n",
      "          2.2236e+00,  2.6607e+00,  1.6451e+00,  1.8297e+00,  9.2207e-01,\n",
      "          1.1769e+00,  7.0753e-01,  1.0861e+00,  2.6390e+00,  2.1608e+00,\n",
      "          1.8213e+00,  2.0916e+00, -5.6040e-01,  1.0475e+00,  2.9005e+00],\n",
      "        [ 2.9025e+00,  4.5705e-01,  1.0470e+00,  2.1244e+00,  9.9745e-01,\n",
      "          1.5728e+00,  1.7845e-01,  1.9553e+00,  1.4868e+00, -9.3775e-02,\n",
      "          2.2980e+00,  2.1890e+00,  1.4109e+00,  1.7099e+00,  1.3415e+00,\n",
      "          1.2749e+00,  7.4001e-01,  1.1328e+00,  2.7566e+00,  2.0792e+00,\n",
      "          1.5457e+00,  2.0875e+00,  1.2499e-01,  1.3103e+00,  2.8871e+00],\n",
      "        [ 2.9759e+00,  1.2317e-01,  9.4486e-01,  1.8914e+00,  1.5905e+00,\n",
      "          1.2838e+00,  8.6548e-02,  1.5246e+00,  1.3086e+00, -1.7193e-01,\n",
      "          2.5856e+00,  2.1052e+00,  1.3382e+00,  2.1659e+00,  1.0764e+00,\n",
      "          1.0660e+00,  1.0020e+00,  1.3408e+00,  2.6459e+00,  1.5835e+00,\n",
      "          1.4726e+00,  2.5091e+00,  9.7022e-02,  1.0830e+00,  2.7178e+00],\n",
      "        [ 2.5009e+00,  3.9050e-01,  1.5067e+00,  2.1557e+00,  1.4134e+00,\n",
      "          1.1258e+00,  4.6020e-01,  1.6710e+00,  9.9936e-01, -7.0150e-02,\n",
      "          1.8962e+00,  2.2180e+00,  1.7863e+00,  1.9858e+00,  1.1203e+00,\n",
      "          1.1215e+00,  1.1604e+00,  1.6359e+00,  2.8709e+00,  1.6400e+00,\n",
      "          1.5128e+00,  2.1815e+00, -3.1027e-01,  5.6082e-01,  2.7236e+00],\n",
      "        [ 2.6874e+00,  3.0263e-01,  9.3978e-01,  2.0662e+00,  1.2138e+00,\n",
      "          1.4543e+00,  4.9961e-01,  1.4906e+00,  1.3610e+00, -2.4651e-01,\n",
      "          1.9948e+00,  2.0023e+00,  1.5042e+00,  1.9357e+00,  1.3249e+00,\n",
      "          1.0950e+00,  9.3822e-01,  1.2091e+00,  3.0671e+00,  2.0349e+00,\n",
      "          2.0815e+00,  2.4173e+00, -2.0381e-01,  8.9539e-01,  2.8031e+00],\n",
      "        [ 2.5735e+00,  1.6427e-02,  1.2362e+00,  2.3001e+00,  1.3718e+00,\n",
      "          1.4202e+00,  6.5934e-02,  1.8155e+00,  1.4967e+00,  3.0540e-01,\n",
      "          2.1410e+00,  2.3713e+00,  1.4108e+00,  2.3878e+00,  1.7243e+00,\n",
      "          8.8262e-01,  6.8920e-01,  1.2114e+00,  2.9587e+00,  1.7759e+00,\n",
      "          1.7889e+00,  2.0528e+00,  9.6348e-02,  8.9211e-01,  2.3297e+00],\n",
      "        [ 2.7294e+00,  2.2382e-01,  1.1726e+00,  2.0356e+00,  9.9813e-01,\n",
      "          2.1384e+00, -2.4634e-01,  1.7912e+00,  1.2587e+00,  3.8825e-01,\n",
      "          2.1077e+00,  2.1333e+00,  1.3338e+00,  1.4639e+00,  1.3960e+00,\n",
      "          1.2456e+00,  5.3573e-01,  1.1487e+00,  2.9506e+00,  1.8088e+00,\n",
      "          2.3099e+00,  2.5742e+00,  2.3054e-01,  1.1514e+00,  2.8633e+00]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [03:21<03:21, 100.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTRAIN OUTPUTS\u001B[39m\u001B[38;5;124m\"\u001B[39m, outputs)\n\u001B[0;32m     15\u001B[0m loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[1;32m---> 16\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     17\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     19\u001B[0m training_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLPProjectVenv\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    494\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NLPProjectVenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    252\u001B[0m     tensors,\n\u001B[0;32m    253\u001B[0m     grad_tensors_,\n\u001B[0;32m    254\u001B[0m     retain_graph,\n\u001B[0;32m    255\u001B[0m     create_graph,\n\u001B[0;32m    256\u001B[0m     inputs,\n\u001B[0;32m    257\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    258\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    259\u001B[0m )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(epochs, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    training_steps = 0\n",
    "    \n",
    "    for step, batch in enumerate(training_dataloader):\n",
    "        inputs = batch[0].to(device)\n",
    "        attention_masks = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        # print(\"TRAIN INPUTS\", inputs)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=attention_masks, labels=labels)\n",
    "        # print(\"TRAIN OUTPUTS\", outputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        training_steps += 1\n",
    "        \n",
    "        training_losses.append(loss.item())\n",
    "        \n",
    "    average_training_loss = training_loss/training_steps\n",
    "    print(f'Epoch:{epoch+1}, Average Training Loss={average_training_loss}')\n",
    "    \n",
    "    model.eval()\n",
    "    validation_accuracy = 0\n",
    "    validation_steps = 0\n",
    "    \n",
    "    for batch in validation_dataloader:\n",
    "        inputs = batch[0].to(device)\n",
    "        attention_masks = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "#         print(\"VAL INPUTS\", inputs)\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(inputs, attention_mask=attention_masks, labels=labels)\n",
    "            \n",
    "        logits = val_outputs.logits\n",
    "        print(\"LOGITS\", logits)\n",
    "        temp_validation_accuracy = accuracy(logits, labels)\n",
    "        validation_accuracy += temp_validation_accuracy\n",
    "        validation_steps += 1\n",
    "        \n",
    "    average_validation_accuracy = validation_accuracy/validation_steps\n",
    "    print(f'Epoch:{epoch+1}, Average Validation Accuracy={average_validation_accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T17:13:55.267965600Z",
     "start_time": "2024-01-28T17:10:33.548790800Z"
    }
   },
   "id": "9d40b9da07c42d0c",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits_list = []\n",
    "labels_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T17:00:47.906483900Z",
     "start_time": "2024-01-28T17:00:47.889484Z"
    }
   },
   "id": "4afa85f661752c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for batch in prediction_dataloader:\n",
    "    inputs = batch[0].to(device)\n",
    "    attention_masks = batch[1].to(device)\n",
    "    labels = batch[2].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, attention_masks)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "    logits_list.append(logits.cpu().numpy())\n",
    "    labels_list.append(labels.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.890484600Z"
    }
   },
   "id": "f6a2177945c9afeb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "matthews_list = []\n",
    "for i in range(len(labels_list)):\n",
    "    mcc = matthews_corrcoef(labels_list[i], numpy.argmax(logits_list[i], axis=1).flatten())\n",
    "    matthews_list.append(mcc)\n",
    "    \n",
    "for i, mcc in enumerate(matthews_list):\n",
    "    print(f'batch {i+1}, MCC = {mcc}')\n",
    "    \n",
    "average_mcc = np.mean(matthews_list)\n",
    "print('Average MCC =', average_mcc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.891484200Z"
    }
   },
   "id": "fba67aa07eb6b73c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OUT OF CODE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a537f1023eff8b2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.892483900Z"
    }
   },
   "id": "862ed469acede438",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wn.synsets('prophetiqmadshiyn')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.893483700Z"
    }
   },
   "id": "9dede2365cd53679",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_lemmas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.894484700Z"
    }
   },
   "id": "9de6d1d2cb80beb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('deployed', 'v')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.895484700Z"
    }
   },
   "id": "973dcc9763ee3aec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_tag"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.896484100Z"
    }
   },
   "id": "de200abb162432",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Watch Cell\n",
    "# print(clean_raw_text(sample_res))\n",
    "# clean_raw_text(sample_res)\n",
    "# nltk.corpus.words.raw().split('\\n')\n",
    "# np.isin(['detail'], nltk.corpus.words.raw().split('\\n'))]\n",
    "def x():\n",
    "    x_dict = nltk.corpus.words.raw().split('\\n')\n",
    "    x_list = [levenshteinDistance('sklearn', word) for word in x_dict]\n",
    "    \n",
    "    id = x_list.index(min(x_list))\n",
    "    print(id)\n",
    "    print(min(x_list))\n",
    "    print(nltk.corpus.words.raw().split('\\n')[id])\n",
    "    \n",
    "x()\n",
    "\n",
    "# lemmatizer.lemmatize('extracting')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.896484100Z"
    }
   },
   "id": "d3a07f1ebda10c20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance as test\n",
    "test('aws', 'reductionqunsobcudt', substitution_cost=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.897483900Z"
    }
   },
   "id": "63d64421478deef8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:00:47.898484Z"
    }
   },
   "id": "be3c47f12dd2ff6a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
